## 01 | 基础架构：一条SQL查询语句是如何执行的？

<img src="F:/项目/Git-md/ZJW-Summary/assets/1685983534586.png" alt="1685983534586" style="zoom: 50%;" />

### 连接器

不要有长链接，可能导致内存占用太大 ，OOM看似MySql重启

### 查询缓存

不建议查缓存

### 分析器

### 优化器

### 执行器





```
1.MySQL的框架有几个组件, 各是什么作用?

连接器：负责跟客户端建立连接、获取权限、维持和管理连接。
查询缓存：查询请求先访问缓存(key 是查询的语句，value 是查询的结果)。命中直接返回。不推荐使用缓存，更新会把缓存清除(关闭缓存：参数 query_cache_type 设置成 DEMAND)。
分析器：对 SQL 语句做解析，判断sql是否正确。
优化器：决定使用哪个索引，多表关联（join）的时候，决定各个表的连接顺序。
执行器：执行语句，先判断用户有无查询权限，使用表定义的存储引擎。

2.Server层和存储引擎层各是什么作用?
Server 层包括连接器、查询缓存、分析器、优化器、执行器等，涵盖 MySQL 的大多数核心服务功能，以及所有的内置函数（如日期、时间、数学和加密函数等），所有跨存储引擎的功能都在这一层实现，比如存储过程、触发器、视图等。

存储引擎层负责数据的存储和提取。其架构模式是插件式的，支持 InnoDB、MyISAM、Memory 等多个存储引擎。现在最常用的存储引擎是 InnoDB，它从 MySQL 5.5.5 版本开始成为了默认存储引擎。

3.you have an error in your SQL syntax 这个保存是在词法分析里还是在语法分析里报错?
分析器,语法分析

4.对于表的操作权限验证在哪里进行?
连接器，执行器

为什么对权限的检查不在优化器之前做？
比如如果有个触发器，得在执行器阶段（过程中）才能确定。优化器阶段前是无能为力的

5.执行器的执行查询语句的流程是什么样的?
1）调用 InnoDB 引擎接口取这个表的第一行，判断 ID 值是不是 10，如果不是则跳过，如果是则将这行存在结果集中；
2)调用引擎接口取“下一行”，重复相同的判断逻辑，直到取到这个表的最后一行。
3）执行器将上述遍历过程中所有满足条件的行组成的记录集作为结果集返回给客户端。
```



## 02 | 日志系统：一条SQL更新语句是如何执行的？

 在一个表上有更新的时候，跟这个表有关的查询缓存会失效 ， 因此不建议使用查询缓存的原因。 

与查询流程不一样的是，更新流程还涉及两个重要的日志模块 

### 重要的日志模块：redo log 

《孔乙己》饭点赊账例子：

 如果有人要赊账或者还账的话，掌柜一般有两种做法：

1、一种做法是直接把账本翻出来，把这次赊的账加上去或者扣除掉；（快）

2、另一种做法是先在粉板上记下这次的账，等打烊以后再把账本翻出来核算。 （费时间）



Mysql同样的问题：

如果每一次的更新操作都需要写进磁盘，然后磁盘也要找到对应的那条记录，然后再更新，整个过程 IO 成本、查找成本都很高。 



MySQL 里经常说到的 WAL 技术，WAL 的全称是 Write-Ahead Logging，它的关键点就是先写日志，再写磁盘（ 这个更新往往是在系统比较空闲的时候做 ），也就是先写粉板，等不忙的时候再写账本。 



```
请教老师，redo log是为了快速响应SQL充当了粉板，这里有两个疑问 
1. redo log本身也是文件，记录文件的过程其实也是写磁盘，那和文中提到的离线写磁盘操作有何区别？
2.  响应一次SQL我理解是要同时操作两个日志文件？也就是写磁盘两次？ 
答案：
1. 写redo log是顺序写，不用去“找位置”，而更新数据需要找位置 
2. 其实是3次（redolog两次 binlog 1次）。不过在并发更新的时候会合并写 
```



 InnoDB 引擎就会先把记录写到 redo log 

<img src="F:/项目/Git-md/ZJW-Summary/assets/1685983832192.png" alt="1685983832192" style="zoom: 50%;" />

 有了 redo log，InnoDB 就可以**保证即使数据库发生异常重启，之前提交的记录都不会丢失**，这个能力称为**crash-safe**。 

**crash-safe**的理解： 只要赊账记录记在了粉板上或写在了账本上，之后即使掌柜忘记了，比如突然停业几天，恢复生意后依然可以通过账本和粉板上的数据明确赊账账目。 



为什么会有两份日志呢？ 

 因为最开始 MySQL 里并没有 InnoDB 引擎。MySQL 自带的引擎是 MyISAM，但是 MyISAM 没有 crash-safe 的能力。



### 重要的日志模块：binlog

 Server 层也有自己的日志，称为 binlog（归档日志） 



#### 三点不同区别

1. redo log 是 InnoDB 引擎特有的；binlog 是 MySQL 的 Server 层实现的，所有引擎都可以使用。
2. redo log 是物理日志，记录的是“在某个数据页上做了什么修改”；binlog 是逻辑日志，记录的是这个语句的原始逻辑，比如“给 ID=2 这一行的 c 字段加 1 ”。
3. redo log 是循环写的，空间固定会用完；binlog 是可以追加写入的。“追加写”是指 binlog 文件写到一定大小后会切换到下一个，并不会覆盖以前的日志。

####  update 语句时的内部流程 

1. **执行器**先找引擎取 ID=2 这一行。ID 是主键，引擎直接用树搜索找到这一行。如果 ID=2 这一行所在的数据页本来就在内存中，就直接返回给执行器；否则，需要先从磁盘读入内存，然后再返回。
2. **执行器**拿到引擎给的行数据，把这个值加上 1，比如原来是 N，现在就是 N+1，得到新的一行数据，再调用引擎接口写入这行新数据。
3. **引擎将这行新数据更新到内存中**，同时将这个**更新操作记录到 redo log** 里面，此时 **redo log 处于 prepare 状态**。然后告知执行器执行完成了，随时可以提交事务。
4. **执行器生成这个操作的 binlog**，并把 binlog 写入磁盘。
5. **执行器**调用**引擎**的提交事务接口，引擎把刚刚写入的 **redo log 改成提交（commit）状态**，更新完成。

<img src="F:/项目/Git-md/ZJW-Summary/assets/1685984149072.png" alt="1685984149072" style="zoom: 67%;" />

图中浅色框表示是在 InnoDB 内部执行的，深色框表示是在执行器中执行的  

### 两阶段提交

作用：两阶段就是保证一致性用的。 

 **怎样让数据库恢复到半个月内任意一秒的状态？** 

 “定期” 全量备份，加binlog

####  为什么日志需要“两阶段提交” 

反证法

1. **先写 redo log 后写 binlog**。假设在 redo log 写完，binlog 还没有写完的时候，MySQL 进程异常重启。由于我们前面说过的，redo log 写完之后，系统即使崩溃，仍然能够把数据恢复回来，所以恢复后这一行 c 的值是 1。
   但是由于 binlog 没写完就 crash 了，这时候 binlog 里面就没有记录这个语句。因此，之后备份日志的时候，存起来的 binlog 里面就没有这条语句。
   然后你会发现，如果需要用这个 binlog 来恢复临时库的话，由于这个语句的 binlog 丢失，这个临时库就会少了这一次更新，恢复出来的这一行 c 的值就是 0，与原库的值不同。
2. **先写 binlog 后写 redo log**。如果在 binlog 写完之后 crash，由于 redo log 还没写，崩溃恢复以后这个事务无效，所以这一行 c 的值是 0。但是 binlog 里面已经记录了“把 c 从 0 改成 1”这个日志。所以，在之后用 binlog 来恢复的时候就多了一个事务出来，恢复出来的这一行 c 的值就是 1，与原库的值不同。

 如果不使用“两阶段提交”  ，那么数据库的状态就有可能和用它的日志恢复出来的库的状态不一致。 

简述：事务是以 binlog 为准的，准确性也以 binlog 为准。

除了误操作恢复数据库的情况，扩容数据库增加读数据能力的时候，也是同样的。 

### 小结

redo log 用于保证 crash-safe 能力。innodb_flush_log_at_trx_commit 这个参数设置成 1 的时候，表示每次事务的 redo log 都直接持久化到磁盘。这个参数我建议你设置成 1，这样可以保证 MySQL 异常重启之后数据不丢失。

sync_binlog 这个参数设置成 1 的时候，表示每次事务的 binlog 都持久化到磁盘。这个参数我也建议你设置成 1，这样可以保证 MySQL 异常重启之后 binlog 不丢失

### 评论

Binlog的形式：

Redo log不是记录数据页“更新之后的状态”，而是记录这个页 “做了什么改动”。

Binlog有两种模式，statement 格式的话是记sql语句， row格式会记录行的内容，记两条，更新前和更新后都有。 



文章中有提到“binlog没有被用来做崩溃恢复”，这是redoLog独有的。

高枕：

我再来说下自己的理解 。

 1 prepare阶段 2 写binlog 3 commit 

当在2之前崩溃时 重启恢复：后发现没有commit，回滚。备份恢复：没有binlog 。 一致 

当在3之前崩溃 重启恢复：虽没有commit，但满足prepare和binlog完整，所以重启后会自动commit。备份：有binlog. 一致 



```
1. redo log的概念是什么? 为什么会存在.
2. 什么是WAL(write-ahead log)机制, 好处是什么.
3. redo log 为什么可以保证crash safe机制.
4. binlog的概念是什么, 起到什么作用, 可以做crash safe吗? 
5. binlog和redolog的不同点有哪些? 
6. 物理一致性和逻辑一直性各应该怎么理解? 
7. 执行器和innoDB在执行update语句时候的流程是什么样的?

1. redo log是重做日志。主要用于MySQL异常重启后的一种数据恢复手段，确保了数据的一致性。归根到底是MySQL为了实现WAL机制的一种手段。因为MySQL进行更新操作，为了能够快速响应，所以采用了异步写回磁盘的技术，写入内存后就返回。但是会存在crash后内存数据丢失的隐患，而redo log具备crash safe能力。

2. WAL机制是写前日志，也就是MySQL更新操作后在真正把数据写入到磁盘前先记录日志。好处是不用每一次操作都实时把数据写盘，就算crash后也可以通过redo log重放恢复，所以能够实现快速响应SQL语句。

3. 因为redo log是每次更新操作完成后，就一定会写入的，如果写入失败，这说明此次操作失败，事务也不可能提交。redo log内部结构是基于页的，记录了这个页的字段值变化，只要crash后读取redo log进行重放就可以恢复数据。（因为redo log是循环写的，如果满了InnoDB就会执行真正写盘）

4. bin log是归档日志，属于MySQL Server层的日志。可以起到全量备份的作用。当需要恢复数据时，可以取出某个时间范围内的bin log进行重放恢复。但是bin log不可以做crash safe，因为crash之前，bin log可能没有写入完全MySQL就挂了。所以需要配合redo log才可以进行crash safe。

5. bin log是Server层，追加写，不会覆盖，记录了逻辑变化，是逻辑日志。redo log是存储引擎层，是InnoDB特有的。循环写，满了就覆盖从头写，记录的是基于页的物理变化，是物理日志，具备crash safe操作。

6. 前者是数据的一致性，后者是行为一致性。（不清楚）

7. 执行器在优化器选择了索引后，调用InnoDB读接口，读取要更新的行到内存中，执行SQL操作后，更新到内存，然后写redo log，写bin log，此时即为完成。后续InnoDB会在合适的时候把此次操作的结果写回到磁盘。
```



顺序总结：

```
1.首先客户端通过tcp/ip发送一条sql语句到server层的SQL interface
2.SQL interface接到该请求后，先对该条语句进行解析，验证权限是否匹配
3.验证通过以后，分析器会对该语句分析,是否语法有错误等
4.接下来是优化器器生成相应的执行计划，选择最优的执行计划
5.之后会是执行器根据执行计划执行这条语句。在这一步会去open table,如果该table上有MDL，则等待。
如果没有，则加在该表上加短暂的MDL(S)
(如果opend_table太大,表明open_table_cache太小。需要不停的去打开frm文件)
6.进入到引擎层，首先会去innodb_buffer_pool里的data dictionary(元数据信息)得到表信息
7.通过元数据信息,去lock info里查出是否会有相关的锁信息，并把这条update语句需要的
锁信息写入到lock info里(锁这里还有待补充)
8.然后涉及到的老数据通过快照的方式存储到innodb_buffer_pool里的undo page里,并且记录undo log修改的redo
(如果data page里有就直接载入到undo page里，如果没有，则需要去磁盘里取出相应page的数据，载入到undo page里)
9.在innodb_buffer_pool的data page做update操作。并把操作的物理数据页修改记录到redo log buffer里
由于update这个事务会涉及到多个页面的修改，所以redo log buffer里会记录多条页面的修改信息。
因为group commit的原因，这次事务所产生的redo log buffer可能会跟随其它事务一同flush并且sync到磁盘上
10.同时修改的信息，会按照event的格式,记录到binlog_cache中。(这里注意binlog_cache_size是transaction级别的,不是session级别的参数,
一旦commit之后，dump线程会从binlog_cache里把event主动发送给slave的I/O线程)
11.之后把这条sql,需要在二级索引上做的修改，写入到change buffer page，等到下次有其他sql需要读取该二级索引时，再去与二级索引做merge
(随机I/O变为顺序I/O,但是由于现在的磁盘都是SSD,所以对于寻址来说,随机I/O和顺序I/O差距不大)
12.此时update语句已经完成，需要commit或者rollback。这里讨论commit的情况，并且双1
13.commit操作，由于存储引擎层与server层之间采用的是内部XA(保证两个事务的一致性,这里主要保证redo log和binlog的原子性),
所以提交分为prepare阶段与commit阶段
14.prepare阶段,将事务的xid写入，将binlog_cache里的进行flush以及sync操作(大事务的话这步非常耗时)
15.commit阶段，由于之前该事务产生的redo log已经sync到磁盘了。所以这步只是在redo log里标记commit
16.当binlog和redo log都已经落盘以后，如果触发了刷新脏页的操作，先把该脏页复制到doublewrite buffer里，把doublewrite buffer里的刷新到共享表空间，然后才是通过page cleaner线程把脏页写入到磁盘中
老师，你看我的步骤中有什么问题嘛？我感觉第6步那里有点问题,因为第5步已经去open table了，第6步还有没有必要去buffer里查找元数据呢?这元数据是表示的系统的元数据嘛,还是所有表的？谢谢老师指正

作者回复: 其实在实现上5是调用了6的过程了的，所以是一回事。MySQL server 层和InnoDB层都保存了表结构，所以有书上描述时会拆开说。

这个描述很详细，同时还有点到我们后面要讲的内通（编辑快来，有人来砸场子啦😄😄）
```





# 03 | 事务隔离：为什么你改了我还看不见？

 SQL 标准的事务隔离级别包括：

- 读未提交（read uncommitted）、

- 读提交（read committed）、

- 可重复读（repeatable read）

- 和串行化（serializable ）。

解释： 

- 读未提交是指，一个事务还没提交时，它做的变更就能被别的事务看到。
- 读提交是指，一个事务提交之后，它做的变更才会被其他事务看到。
- 可重复读是指，一个事务执行过程中看到的数据，总是跟这个事务在启动时看到的数据是一致的。当然在可重复读隔离级别下，未提交变更对其他事务也是不可见的。
- 串行化，顾名思义是对于同一行记录，“写”会加“写锁”，“读”会加“读锁”。当出现读写锁冲突的时候，后访问的事务必须等前一个事务执行完成，才能继续执行。

来自评论：

读未提交：别人改数据的事务尚未提交，我在我的事务中也能读到。 

读已提交：别人改数据的事务已经提交，我在我的事务中才能读到。 

可重复读：别人改数据的事务已经提交，我在我的事务中也不去读。

串行：我的事务尚未提交，别人就别想改数据。 这4种隔离级别，并行性能依次降低，安全性依次提高。 



### 事务隔离级别的配置方法？

启动参数transaction-isolation ， READ-COMMITTED。 

### 可重复读的使用场景

对账，判断上个月的余额和当前余额的差额，是否与本月的账单明细一致。你一定希望在校对过程中，即使有用户发生了一笔新的交易，也不影响你的校对结果。  事务启动时的视图可以认为是静态的，不受其他事务更新的影响。 



<img src="F:/项目/Git-md/ZJW-Summary/assets/1685986974010.png" alt="1685986974010" style="zoom:50%;" />

### 事务隔离的实现

<img src="F:/项目/Git-md/ZJW-Summary/assets/1686833772636.png" alt="1686833772636" style="zoom: 67%;" />

每条记录在更新的时候都会有回滚链表。

不同时刻启动的事务会有不同的 read-view。 

在视图 A、B、C 里面，这一个记录的值分别是 1、2、4，同一条记录在系统中可以存在多个版本，就是数据库的多版本并发控制（MVCC） 



### 回滚日志什么时候删除？

系统会判断，当没有事务再需要用到这些回滚日志时， 也就是当系统里没有比这个回滚日志更早的 read-view 的时候。 ，回滚日志会被删除。 



### 为什么不要有长事务？

1、长事务意味着系统里面会存在很老的事务视图。 

2、长事务占用锁资源，拖垮数据库。 

3、大事务会导致主从延迟。

 我见过数据只有 20GB，而回滚段有 200GB 的库。最终只好为了清理回滚段，重建整个库。 

 除了对回滚段的影响，长事务还占用锁资源，也可能拖垮整个库 。



长事务日志查询语句

超过60秒的：select * from information_schema.innodb_trx where TIME_TO_SEC(timediff(now(),trx_started))>60



### 事务的启动方式

1. 显式：启动事务语句， begin 或 start transaction。配套的提交语句是 commit，回滚语句是 rollback。
2. 隐式：set autocommit=0，这个命令会将这个线程的自动提交关掉。意味着如果你只执行一个 **select** 语句，这个事务就启动了，而且并不会自动提交。这个事务持续存在直到你主动执行 **commit 或 rollback** 语句，或者**断开连接。**

 建议你总是使用 set autocommit=1, 通过显式语句的方式来启动事务。

如果要减少了语句的交互次数。建议你使用 commit work and chain 语法。  减少显式事务所需要的begin语句。

### 上期问题

 周期备份：一天一备跟一周一备的对比 ，频繁坏处： 需要消耗更多存储空间 





# 04 | 深入浅出索引（上）

### 索引的常见模型

 常见索引模型：哈希表、有序数组、搜索树 

 **哈希表这种结构适用于只有等值查询的场景**（没顺序），比如 Memcached 及其他一些 NoSQL 引擎。 

 **有序数组索引只适用于静态存储引擎** （效率高，修改挪值麻烦）

 **二叉搜索树**

100 万节点的平衡二叉树，树高 20。一次查询可能需要访问 20 个数据块。在机械硬盘时代，从磁盘随机读一个数据块需要 10 ms 左右的寻址时间。也就是说，对于一个 100 万行的表，如果使用二叉树来存储，单独访问一个行可能需要 20 个 10 ms 的时间，这个查询可真够慢的。 

N叉树

 100 万节点的平衡二叉树，树高 20。一次查询可能需要访问 20 个数据块。在机械硬盘时代，从磁盘随机读一个数据块需要 10 ms 左右的寻址时间。也就是说，对于一个 100 万行的表，如果使用二叉树来存储，单独访问一个行可能需要 20 个 10 ms 的时间，这个查询可真够慢的。 

 考虑到树根的数据块总是在内存中的，一个 10 亿行的表上一个整数字段的索引，查找一个值最多只需要访问 3 次磁盘。其实，树的第二层也有很大概率在内存中，那么访问磁盘的平均次数就更少了。 

### InnoDB 的索引模型

 每一个索引在 InnoDB 里面对应一棵 B+ 树。 

### 索引维护

为什么要自增主键？

普通插入会**挪值**，如果 R5 所在的数据页已经满了，根据 B+ 树的算法，这时候需要申请一个新的数据页，然后挪动部分数据过去。这个过程称为**页分裂** ，删除，会页合并

**显然，主键长度越小，普通索引的叶子节点就越小，普通索引占用的空间也就越小。**

所以，从性能和存储空间方面考量（避免存的主键空间占用大，且数据页易满易分裂），自增主键往往是更合理的选择。



### 上期问题

 如何避免长事务对业务的影响？ 

 开发端来看： 

1、通过 general_log 的日志来确认  set autocommit 的值。你的目标就是把它改成 1。 

2、 不必要的只读事务 

3、 根据业务本身的预估，通过 SET MAX_EXECUTION_TIME 命令，来控制每个语句执行的最长时间 。



 数据库端来看： 

1、 监控 information_schema.Innodb_trx 表，设置长事务阈值，超过就报警 / 或者 kil 

2、 测试阶段要求输出所有的 general_log，分析日志行为提前发现问题 

### 评论

 “N叉树”的N值在MySQL中是可以被人工调整的么？ 

可以通过索引本身的key大小和存储单元本身的page页大小来进而影响 N 值。

```js
1，通过改变key值来调整
N叉树中非叶子节点存放的是索引信息，索引包含Key和Point指针。Point指针固定为6个字节，假如Key为10个字节，那么单个索引就是16个字节。如果B+树中页大小为16K，那么一个页就可以存储1024个索引，此时N就等于1024。我们通过改变Key的大小，就可以改变N的值
2，改变page页的大小
页越大，一页存放的索引就越多，N就越大。

key的值也可以认为是固定的，通常就是4或者8，int或者bigint.主要还是page大小。

数据页调整后，如果数据页太小层数会太深。
数据页太大，加载到内存的时间和单个数据页查询时间会提高，需要达到平衡才行。

默认情况下，表空间中的页大小都为 16KB，当然也可以通过改变 innodb_page_size 选项对默认大小进行修改，需要注意的是不同的页大小最终也会导致区大小的不同
```





# 05 | 深入浅出索引（下）

### 覆盖索引

### 最左前缀原则

 在建立联合索引的时候，如何安排索引内的字段顺序？

第一，顺序，第二， **考虑的原则就是字段存储空间** 

### 索引下推

 MySQL 5.6 引入的索引下推优化（index condition pushdown)， 可以在索引遍历过程中（联合索引），对索引中包含的字段先做判断，直接过滤掉不满足条件的记录，减少回表次数。 



### 上期问题

 对于上面例子中的 InnoDB 表 T，如果你要**重建索引 k**，你的两个 SQL 语句可以这么写： 

1、 如果你要重建索引 k 

 alter table T drop index k;

alter table T add index(k); 

2、 如果你要重建主键索引，也可以这么写： 

alter table T drop primary key;
alter table T add primary key(id);



 重建索引 k 的做法是合理的，可以达到省空间的目的。 

 重建主键的过程不合理。不论是删除主键还是创建主键，都会将整个表重建。 

```
1. 直接删掉主键索引是不好的，它会使得所有的二级索引都失效，并且会用ROWID来作主键索引；
2. 看到mysql官方文档写了三种措施:
第一个是整个数据库迁移，先dump出来再重建表（这个一般只适合离线的业务来做）；
第二个是用空的alter操作，比如ALTER TABLE t1 ENGINE = InnoDB;这样子就会原地重建表结构（真的吗？）；
第三个是用repaire table，不过这个是由存储引擎决定支不支持的（innodb就不行）。
```



### 评论

```
老师，下面两条语句有什么区别，为什么都提倡使用2:
1.select * from T where k in(1,2,3,4,5) 
2.select * from T where k between  1 and 5

好问题，
第一个要树搜素5次
第二个搜索一次
```





# 06 | 全局锁和表锁 ：给表加个字段怎么有这么多阻碍？

 **根据加锁的范围，MySQL 里面的锁大致可以分成全局锁、表级锁和行锁三类**。 

###  全局锁

 全局锁就是对整个数据库实例加锁。 所有改表、字段等都阻塞。 

命令： Flush tables with read lock (**FTWRL**)。 

这个命令可以使整个库处于只读状态。使用该命令之后，数据更新语句、数据定义语句和更新类事务的提交语句等操作都会被阻塞。 

 **全局锁的典型使用场景是，做全库逻辑备份。**也就是把整库每个表都 select 出来存成文本。  

MyISAM 这种不支持事务的引擎 ，所以有这个必要。



其他引擎备份数据（innodb），官方自带的逻辑备份工具是 mysql dump。  MVCC 的支持。



 **要全库只读，为什么不使用 set global readonly=true 的方式呢**？ 

答：

1、系统层面：修改 global 变量，影响更大，  global readonly 也常常用来判断一个库是主库还是备库 。建议FTWRL

2、 异常处理机制上， 执行 FTWRL 命令之后由于客户端发生异常断开，锁会释放。 整个库回到可以正常更新的状态 。 将整个库设置为 readonly 之后，没有回退，风险较高。



### 表级锁

 表级别的锁有两种：一种是表锁，一种是元数据锁（meta data lock，MDL)。 

#### 表锁的语法

lock tables … read/write。与 FTWRL 类似 ，异常自动释放。

作用：早期用来做并发控制（有行锁一般不用这个锁），对于 InnoDB 这种支持行锁的引擎，一般不使用 lock tables 命令来控制并发。 InnoDB 建议使用 –single-transaction 参数 



#### 元数据锁 MDL

 MySQL 5.5 版本中引入了 MDL。

作用：防止表结构变更，造成查询前后数据结果和原始表结构的不一致。 MDL作用是防止DDL和DML并发的冲突

当对一个表**做增删改查**操作的时候，加 MDL 读锁；

当要对表做**结构变更**操作的时候，加 MDL 写锁。 



互斥情况：

 读锁之间不互斥 

 读写锁之间、写锁之间是互斥的 



加锁时机：

 事务中的 MDL 锁，在语句执行开始时申请，但是语句结束后并不会马上释放，而会等到整个事务提交后再释放。 

<img src="F:/项目/Git-md/ZJW-Summary/assets/1686844930271.png" alt="1686844930271" style="zoom:67%;" />

 实验环境是 MySQL 5.6。 



####  **如何安全地给小表加字段？** 

在 alter table 语句里面设定等待时间，如果在这个指定的等待时间里面能够拿到 MDL 写锁最好，拿不到也不要阻塞后面的业务语句，先放弃。之后开发人员或者 DBA 再通过重试命令重复这个过程。 

ALTER TABLE tbl_name NOWAIT add column ...

ALTER TABLE tbl_name WAIT N add column ... 



### 评论

mysql 5.6不是支持online ddl了吗？也就是对表操作增加字段等功能，实际上不会阻塞读写？

```
作者：
Online DDL的过程是这样的：
1. 拿MDL写锁
2. 降级成MDL读锁
3. 真正做DDL
4. 升级成MDL写锁
5. 释放MDL锁

1、2、4、5如果没有锁冲突，执行时间非常短。第3步占用了DDL绝大部分时间，这期间这个表可以正常读写数据，是因此称为“online ”,我们文中的例子，是在第一步就堵住了

其他同学：
第三步中真正做DDL时，不是在当前表上做的，是新建的别的表。所以第四步中需要将旧表和新表换名字，这个过程必须要阻塞DML，所以需要加写锁。

搜了下，mysql在线ddl(加字段、加索引等修改表结构之类的操作）过程如下：
1 对表加锁(表此时只读)
2 复制原表物理结构，创建新中间表
3 修改中间表的物理结构
4 把原表数据导入中间表中，数据同步完后，锁定中间表，并删除原表
5 rename中间表为原表
6 刷新数据字典，并释放锁

原生online ddl的原理与适用场景，参考博文：https://opensource.actionsky.com/20200916-ddl/
```

# 07 | 行锁功过：怎么减少行锁对性能的影响？

###  两阶段锁

 在 InnoDB 事务中，行锁是在需要的时候才加上的，但并不是不需要了就立刻释放，而是要等到事务结束时才释放。这个就是两阶段锁协议。 

###  对我们使用事务有什么帮助呢？

那就是，如果你的事务中需要锁多个行，要把最可能造成锁冲突、最可能影响并发度的锁尽量往后放。 

简述：因为用到的行才会上锁，所以，大锁的SQL放后边执行。



### 业务中3个SQL的顺序编排？

```
从顾客 A 账户余额中扣除电影票价；
给影院 B 的账户余额增加这张电影票价；
记录一条交易日志。

如果同时有另外一个顾客 C 要在影院 B 买票，那么这两个事务冲突的部分就是语句 2 了。因为它们要更新同一个影院账户的余额，需要修改同一行数据。

答案：
根据两阶段锁协议，不论你怎样安排语句顺序，所有的操作需要的行锁都是在事务提交的时候才释放的。所以，如果你把语句 2 安排在最后，比如按照 3、1、2 这样的顺序，那么影院账户余额这一行的锁时间就最少。这就最大程度地减少了事务之间的锁等待，提升了并发度。
```



### 死锁

锁超时时间 innodb_lock_wait_timeout 来设置。 默认50s 不靠谱，太短会误伤。

死锁检测： innodb_deadlock_detect 设置为 on，表示开启这个逻辑。 会消耗资源来进行检测。



### 死锁检测

每当一个事务被锁的时候，就要看看它所依赖的线程有没有被别人锁住，如此循环，最后判断是否出现了循环等待，也就是死锁。  这是一个时间复杂度是 O(n) 的操作 。



作者评论：理论上说，之前没死锁，现在A加进来，出现了死锁，那么死锁的环里面肯定包含A， 因此只要从A出发去扫就好了 



### 热点行更新的性能问题？

问题的症结在于，死锁检测要耗费大量的 CPU 资源。 

1、关闭死锁检测。会出现很多超时，可能有损业务。只是死锁的话，加上业务重试，业务能无损。

2、并发控制。要做在Mysql里面。客户端的并发控制不能完全管住这种问题。

3、数据分散到多行。 影院的账户总额等于这 10 个记录的值的总和。这样每次要给影院账户加金额的时候，随机选其中一条记录来加。 

需要更多业务逻辑设计，比如退票逻辑，那么这时候就需要考虑当一部分行记录变成 0 的时候，代码要有特殊处理。 



### 评论

```
问题一、
什么时候会有死锁检测？任何查询、更新都会有吗？

如果他要加锁访问的行上有锁，他才要检测。
这里面我担心你有两个误解，说明下：
1.一致性读不会加锁，就不需要做死锁检测；
2.并不是每次死锁检测都都要扫所有事务。比如某个时刻，事务等待状态是这样的：
   B在等A，
   D在等C，
   现在来了一个E，发现E需要等D，那么E就判断跟D、C是否会形成死锁，这个检测不用管B和A
   
   
问题二、
innodb行级锁是通过锁索引记录实现的。如果update的列没建索引，即使只update一条记录也会锁定整张表吗？
比如update t set t.name='abc' where t.name='cde';   name字段无索引。 

是会锁全表的。试想，你的update 语句后面加个limit 1, 会怎么锁？ 
答案是锁扫描过的记录。
```



# 08 | 事务到底是隔离的还是不隔离的？

 专栏里都是默认 autocommit=1。 



事务视图的不同起点：

 begin/start transaction 命令并不是一个事务的起点，在执行到它们之后的第一个操作 InnoDB 表的语句，事务才真正启动。

如果你想要马上启动一个事务，可以使用 start transaction with consistent snapshot 这个命令。 

1、第一种启动方式，一致性视图是在执行第一个快照读语句时创建的；

2、第二种启动方式，一致性视图是在执行 start transaction with consistent snapshot 时创建的。 



<img src="F:/项目/Git-md/ZJW-Summary/assets/1686895050701.png" alt="1686895050701" style="zoom:67%;" />

 如果我告诉你事务 B 查到的 k 的值是 3，而事务 A 查到的 k 的值是 1，你是不是感觉有点晕呢？ 



视图概念：

1、 一个是 view。它是一个用查询语句定义的虚拟表 。创建视图的语法是 create view … ，而它的查询方法与表一样。 

2、 另一个 是 InnoDB 在实现 MVCC 时用到的一致性读视图，即 consistent read view，用于支持 RC（Read Committed，读提交）和 RR（Repeatable Read，可重复读）隔离级别的实现 



###  “快照”在 MVCC 里是怎么工作的？ 

 在可重复读隔离级别下 ， 事务在启动的时候就“拍了个快照” ， 快照是基于整库的。 

 InnoDB 里面每个事务有一个唯一的事务 ID，叫作 transaction id。它是在事务开始的时候向 InnoDB 的事务系统申请的，是按申请顺序严格递增的。 

而每行数据也都是有多个版本的。每次事务更新数据的时候，都会生成一个新的数据版本，并且把 transaction id 赋值给这个数据版本的事务 ID，记为 row trx_id。同时，旧的数据版本要保留，并且在新的数据版本中，能够有信息可以直接拿到它。也就是说，数据表中的一行记录，其实可能有多个版本 (row)，每个版本有自己的 row trx_id。如图 2 所示，就是一个记录被多个事务连续更新后的状态。 

<img src="F:/项目/Git-md/ZJW-Summary/assets/1686895084315.png" alt="1686895084315" style="zoom:67%;" />

 内容过于详细，case具体看得。





 一个数据版本，对于一个事务视图来说，除了自己的更新总是可见以外，有三种情况：

- 版本未提交，不可见；
- 版本已提交，但是是在视图创建后提交的，不可见；
- 版本已提交，而且是在视图创建前提交的，可见。 



### 小结

InnoDB 的行数据有多个版本，每个数据版本有自己的 row trx_id，每个事务或者语句有自己的一致性视图。普通查询语句是一致性读，一致性读会根据 row trx_id 和一致性视图确定数据版本的可见性。

- 对于可重复读，查询只承认在事务启动前就已经提交完成的数据；

- 对于读提交，查询只承认在语句启动前就已经提交完成的数据；

而当前读，总是读取已经提交完成的最新版本。 



### 评论

同学：

当开启事务时，需要保存活跃事务的数组（A），然后获取高水位（B）。我的疑问就是，在这两个动作之间（A和B之间）会不会产生新的事务？如果产生了新的事务，那么这个新的事务相对于当前事务就是可见的，不管有没有提交。 

作者：

 代码实现上，获取视图数组和高水位是在事务系统的**锁**保护下做的，**可以认为是原子操作，期间不能创建事务。** 



同学自问自答：

为什么rr能实现可重复读而rc不能？

分两种情况 ：

(1)快照读的情况下,rr不能更新事务内的up_limit_id,    而rc每次会把up_limit_id更新为快照读之前最新已提交事务的transaction id,则rc不能可重复读

(2)当前读的情况下,rr是利用record lock+gap lock来实现的,而rc没有gap,所以rc不能可重复读 



# 09 | 普通索引和唯一索引，应该怎么选择？

### 身份证索引选择

主键和非主键的索引树 搜索方法不同，但是效率差异微乎其微因为innoDB的数据读取是以数据页为单位的。

### InnoDB 的数据读取

InnoDB 的数据是按数据页为单位来读写的。也就是说，当需要读一条记录的时候，并不是将这个记录本身从磁盘读出来，而是以页为单位，将其整体读入内存。在 InnoDB 中，每个数据页的大小默认是 16KB。 

 对于整型字段，一个数据页可以放近千个 key 

###  更新过程 

###  change buffer介绍

 当需要更新一个数据页时，如果数据页在内存中就直接更新，而如果这个数据页还没有在内存中的话，在不影响数据一致性的前提下，InnoDB 会将这些更新操作缓存在 change buffer 中，这样就不需要从磁盘中读入这个数据页了。在下次查询需要访问这个数据页的时候，将数据页读入内存，然后执行 change buffer 中与这个页有关的操作。通过这种方式就能保证这个数据逻辑的正确性。需要说明的是，虽然名字叫作 change buffer，实际上它是可以持久化的数据。也就是说，change buffer 在内存中有拷贝，也会被写入到磁盘上。将 change buffer 中的操作应用到原数据页，得到最新结果的过程称为 merge。除了访问这个数据页会触发 merge 外，系统有后台线程会定期 merge。在数据库正常关闭（shutdown）的过程中，也会执行 merge 操作。显然，如果能够将更新操作先记录在 change buffer，减少读磁盘，语句的执行速度会得到明显的提升。而且，数据读入内存是需要占用 buffer pool 的，所以这种方式还能够避免占用内存，提高内存利用率。 



###  change buffer使用场景

 change buffer 只限于用在普通索引的场景下，而不适用于唯一索引。 

 对于写多读少的业务来说，页面在写完以后马上被访问到的概率比较小（被立刻访问就会立刻merge， change buffe缓存的更新操作越多，它本身的性价比就越高），此时 change buffer 的使用效果最好。这种业务模型常见的就是账单类、日志类的系统。 



### 索引的选择

就身份证而言，主键非主键，查询性能没什么差别，就看更新性能。 所以建议你尽量选择普通索引。 

 如果所有的更新后面，都马上伴随着对这个记录的查询，那么你应该关闭 change buffer。而在其他情况下，change buffer 都能提升更新性能。 

 在实际使用中，你会发现，普通索引和 change buffer 的配合使用，对于数据量大的表的更新优化还是很明显的。 

和redo log 都是  尽量减少随机读写 的思想提升性能。



建议：

由于唯一索引用不上 change buffer 的优化机制，因此如果业务可以接受（业务要求第一优先），从性能角度出发我建议你优先考虑非唯一索引。 

 “归档库”的场景， 可以优先考虑非唯一索引。



 如果碰上了大量插入数据慢、内存命中率低的时候，可以给你多提供一个排查思路。 

### redo log和change buffer对比

 如果要简单地对比这两个机制在提升更新性能上的收益的话，redo log 主要节省的是随机写磁盘的 IO 消耗（转成顺序写），而 change buffer 主要节省的则是随机读磁盘的 IO 消耗。 



### 评论

作者：

 insert的时候，写主键是肯定不能用change buffer了，但是同时也会要写其它索引，而其它索引中的“非唯一索引”是可以用的这个机制的； 第二段，你搜出来的这个不太完整。是这样的，change buffer的前身是insert buffer,只能对insert 操作优化；后来升级了，增加了update/delete的支持，名字也改叫change buffer. 



# 10 | MySQL为什么有时候会选错索引？

###   优化器的逻辑 

在数据库里面，扫描行数是影响执行代价的因素之一。扫描的行数越少，意味着访问磁盘数据的次数越少，消耗的 CPU 资源越少。 

 当然，**扫描行数**并不是唯一的判断标准，优化器还会结合**是否使用临时表、是否排序**等因素进行综合判断。 



###  扫描行数是怎么判断的？ 

 估算记录数。 

 一个索引上不同的值的个数，我们称之为“基数”  （cardinality） ， 这个基数越大，索引的区分度越好。 



  MySQL 是怎样得到索引的基数的呢？ 

采样统计的时候，InnoDB 默认会选择 N 个数据页，统计这些页面上的不同值，得到一个平均值，然后乘以这个索引的页面数，就得到了这个索引的基数。 



 数据在不断变更，当变更的数据行数超过 1/M 的时候，会自动触发重新做一次索引统计 。



### 存储索引统计的方式

 在 MySQL 中，有两种存储索引统计的方式，可以通过设置参数 innodb_stats_persistent 的值来选择：

- 设置为 on 的时候，表示统计信息会**持久化存储**。这时，默认的 N 是 20，M 是 10。
- 设置为 off 的时候，表示统计信息**只存储在内存中**。这时，默认的 N 是 8，M 是 16。 

然而没什么差别，都是不准的。

###  重新统计索引 

 analyze table t 命令，可以用来重新统计索引信息。  如果你发现 explain 的结果预估的 rows 值跟实际情况差距比较大，可以采用这个方法来处理。 



###  优化器误判的处理

优化器：宁愿扫描更多行数，也不愿意排序。

没有很通用的方法，需要case by case：

1、 force index 来强行指定索引 

2、 通过修改语句来引导优化器，前提还不能影响业务，最好要有代码注释。

3、增加、删除索引。



### 上期问题

问题： 如果某次写入使用了 change buffer 机制，之后主机异常重启，是否会丢失 change buffer 和数据。 

答案： 这个问题的答案是不会丢失，留言区的很多同学都回答对了。虽然是只更新内存，但是在事务提交的时候，我们把 change buffer 的操作也记录到 redo log 里了，所以崩溃恢复的时候，change buffer 也能找回来。 



问题： merge 的过程是否会把数据直接写回磁盘，这是个好问题。这里，我再为你分析一下。 

```js
作者：merge 的执行流程是这样的：
1、从磁盘读入数据页到内存（老版本的数据页）；
2、从 change buffer 里找出这个数据页的 change buffer 记录 (可能有多个），依次应用，得到新版数据页；
3、写 redo log。这个 redo log 包含了数据的变更和 change buffer 的变更。

到这里 merge 过程就结束了。这时候，数据页和内存中 change buffer 对应的磁盘位置都还没有修改，属于脏页，之后各自刷回自己的物理数据，就是另外一个过程了。
```

# 11 | 怎么给字符串字段加索引？

### 前缀索引的使用

邮箱号当做查询条件的场景

使用前缀索引，定义好长度，就可以做到既节省空间，又不用额外增加太多的查询成本。 

### 前缀多长合适？

按照不同前缀长度来，统计基数的比率。业务要满足95%？

###  前缀索引对覆盖索引的影响 

 使用前缀索引就用不上覆盖索引对查询性能的优化了，这也是你在选择是否使用前缀索引时需要考虑的一个因素。 



### 身份证区分度低怎么处理？

1、 第一种方式是使用倒序存储。 

2、 第二种方式是使用 hash 字段。  在表上再创建一个整数字段，来保存身份证的校验码，同时在这个字段上创建索引。 

这两种就都不支持范围查询了，都只是等值查询。



### 总结

```
1、直接创建完整索引，这样可能比较占用空间；
2、创建前缀索引，节省空间，但会增加查询扫描次数，并且不能使用覆盖索引；
3、倒序存储，再创建前缀索引，用于绕过字符串本身前缀的区分度不够的问题；
4、创建 hash 字段索引，查询性能稳定，有额外的存储和计算消耗，跟第三种方式一样，都不支持范围扫描。
```



# 12 | 为什么我的MySQL会“抖”一下？

### 脏页、干净页

 当内存数据页跟磁盘数据页内容不一致的时候，我们称这个内存页为“脏页”。内存数据写入到磁盘后，内存和磁盘上的数据页的内容就一致了，称为“干净页”。 



### 为什么抖动？

 你不难想象，平时执行很快的更新操作，其实就是在写内存和日志，而 MySQL 偶尔“抖”一下的那个瞬间，可能就是在刷脏页（flush）。 



 什么情况会引发数据库的 flush 过程呢？ 

1、 第一种场景是，粉板满了，记不下了 

2、 对应的就是系统内存不足。 

3、 MySQL 认为系统“空闲”的时候。 

4、 MySQL 正常关闭的情况 



分析1、2：

 InnoDB 用缓冲池（buffer pool）管理内存，缓冲池中的内存页有三种状态： 

```
第一种是，还没有使用的；
第二种是，使用了并且是干净页；
第三种是，使用了并且是脏页。
```

 InnoDB 的策略是尽量使用内存，因此对于一个长时间运行的库来说，未被使用的页面很少。 

 刷脏页虽然是常态，但是出现以下这两种情况，都是会明显影响性能的： 



1、 一个查询要淘汰的脏页个数太多，会导致查询的响应时间明显变长；

2、日志写满，更新全部堵住，写性能跌为 0，这种情况对敏感业务来说，是不能接受的。

所以，InnoDB 需要有控制脏页比例的机制，来尽量避免上面的这两种情况。 

###  InnoDB 刷脏页的控制策略 

 这就要用到 innodb_io_capacity 这个参数了，它会告诉 InnoDB 你的磁盘能力。这个值我建议你设置成磁盘的 IOPS。 



 设计策略控制刷脏页的速度，会参考哪些因素呢？ 

刷的太快会磁盘响应别的不及时，刷慢了redolog容易满。

 InnoDB 的刷盘速度就是要参考这两个因素：一个是脏页比例，一个是 redo log 写盘速度。 



 参数 innodb_max_dirty_pages_pct 是脏页比例上限，默认值是 75%。平时要多关注脏页比例，不要让它经常接近 75%。 



### 邻居策略

 flush 掉一个脏页时 ， 如果这个数据页旁边的数据页刚好是脏页，就会把这个“邻居”也带着一起刷掉 ， 而且这个把“邻居”拖下水的逻辑还可以继续蔓延 。



 在 InnoDB 中，innodb_flush_neighbors 参数，就是用来控制这个行为的，值为 1 的时候会有上述的“连坐”机制，值为 0 时表示不找邻居，自己刷自己的。 



 机械硬盘 有意义， IOPS 一般只有几百， 相同的逻辑操作减少随机 IO 就意味着系统性能的大幅度提升。 

SSD硬盘， IOPS 比较高的设备 ， 这时候 IOPS 往往不是瓶颈 。值设置为0即可。 MySQL 8.0 默认就是0



# 13 | 为什么表数据删掉一半，表文件大小不变？

###  参数 innodb_file_per_table 

 建议你不论使用 MySQL 的哪个版本，都将这个值设置为 ON。因为，一个表单独存储为一个文件更容易管理，而且在你不需要这个表的时候，通过 drop table 命令，系统就会直接删除这个文件。而如果是放在共享表空间中，即使表删掉了，空间也是不会回收的。 

### 小结

 讨论了数据库中收缩表空间的方法。

现在你已经知道了，如果要收缩一个表，只是 delete 掉表里面不用的数据的话，表文件的大小是不会变的。

你还要通过 alter table 命令重建表，才能达到表文件变小的目的。

我跟你介绍了重建表的两种实现方式（非Online更不考虑了），Online DDL 的方式是可以考虑在业务低峰期使用的，而 MySQL 5.5 及之前的版本，这个命令是会阻塞 DML 的，这个你需要特别小心。 

# 14 | count(*)这么慢，我该怎么办？

###  count(*) 的实现方式 

1、 MyISAM 引擎把一个表的总行数存在了磁盘 （前提是没有where条件）

2、 InnoDB 引擎就麻烦了 ，执行的时候一行一行的读



###  InnoDB 算count（*）

 InnoDB 算count（*），MySQL 优化器会找到最小的那棵树来遍历。  在保证逻辑正确的前提下，尽量减少扫描的数据量，是数据库系统设计的通用法则之一。 



### 能不能用 show table status 查看多少行？

 show table status 命令显示的行数也不能直接使用。 

### 怎么解决计数问题？

redis必有偏大、偏小的情况。单独领出一个表用事务来计数是可以解决的。

###  不同的 count 用法 

 count(*)、count(主键 id)、count(字段) 和 count(1) 等不同用法的性能差别。

结果：

 count(1) 执行得要比 count(主键 id) 快。因为从引擎返回 id 会涉及到解析数据行，以及拷贝字段值的操作。 

 count(1) 不取值，count(id) 取id这个值。

count(字段)，取值，且判断null不计数。从字段定义上可以省去这个判断。

 但是 count(\*) 是例外，并不会把全部字段取出来，而是专门做了优化，不取值。count(*) 肯定不是 null，按行累加。 

 所以结论是：按照效率排序的话，count(字段) <count(主键 id)<count(1)≈count(\*)，所以我建议你，尽量使用 count(*)。

# 16 | “order by”是怎么工作的？

<img src="F:/项目/Git-md/ZJW-Summary/assets/1686924499182.png" alt="1686924499182" style="zoom:50%;" />

 sort_buffer_size，就是 MySQL 为排序开辟的内存（sort_buffer）的大小。如果要排序的数据量小于 sort_buffer_size，排序就在内存中完成。但如果排序数据量太大，内存放不下，则不得不利用磁盘临时文件辅助排序。 

### 内存排序和临时文件排序

 sort_buffer_size 越小，需要分成的份数越多，number_of_tmp_files 的值就越大。 

临时文件排序，是用的归并算法。



缺陷：

如果查询要返回的字段很多的话，那么 sort_buffer 里面要放的字段数太多，这样内存里能够同时放下的行数很少，要分成很多个临时文件，排序的性能会很差。所以如果单行很大，这个方法效率不够好。 

###  如果 MySQL 认为排序的单行长度太大会怎么做呢？ 

 max_length_for_sort_data，是 MySQL 中专门控制用于排序的行数据的长度的一个参数。它的意思是，如果单行的长度超过这个值（多字段定义的实际长度累加），MySQL 就认为单行太大，要换一个算法。 



 rowid 排序 

<img src="F:/项目/Git-md/ZJW-Summary/assets/1686925050783.png" alt="1686925050783" style="zoom:67%;" />

 rowid 排序多访问了一次表 t 的主键索引，就是步骤 7。 

###  全字段排序 VS rowid 排序 

rowid 排序 比全字段排序多一次主键索引的回表查询。

全字段是buffer足够放下所有字段，直接排序完就可以返回。rowid 排序是无奈放不下，只能放部分字段到buffer里，比如就放 要排序的 name 、id。最后回表再查出 name、city、age等。



 如果 MySQL 实在是担心排序内存太小，会影响排序效率，才会采用 rowid 排序算法，这样排序过程中一次可以排序更多行，但是需要再回到原表去取数据。

如果 MySQL 认为内存足够大，会优先选择全字段排序，把需要的字段都放到 sort_buffer 中，这样排序后就会直接从内存里面返回查询结果了，不用再回到原表去取数据。



这也就体现了 MySQL 的一个设计思想：如果内存够，就要多利用内存，尽量减少磁盘访问。 

 对于 InnoDB 表来说，rowid 排序会要求回表多造成磁盘读，因此不会被优先选择。 



另一种排序情况：天然有序，联合索引、覆盖索引。



###  上期问题 

和库里面相同的值用sql去update，mysql会进行更新操作吗？会且会锁行等。也会把事务最新id更新到记录的版本id上。

mysql 是否会更新前判断一下值是不是相同吗？如果判断一下，不就不用浪费 InnoDB 操作，多去更新一次了？ 

<img src="F:/项目/Git-md/ZJW-Summary/assets/1686926867145.png" alt="1686926867145" style="zoom:67%;" />

但是这两图的update 语句不同。

<img src="F:/项目/Git-md/ZJW-Summary/assets/1686926902878.png" alt="1686926902878" style="zoom:67%;" />

能给到mysql做判断的东西不同，图13，只能知道id的值，图14mysql可以知道并比对 id =1 和 a= 3。通过前后事务版本是否更新来判断mysql的实际走向。

# 17 | 如何正确地显示随机消息？

### 排序算法的选择

问题：单词软件随机查出3个用户过去搜过的单词。

分析： Extra 字段显示 Using temporary，表示的是需要使用**临时表**；Using filesort，表示的是需要执行排序操作。 



 对于 InnoDB 表来说，执行全字段排序会减少磁盘访问，因此会被优先选择。 

但是，我强调了“InnoDB 表”，你肯定想到了，**对于内存表**，回表过程只是简单地根据数据行的位置，直接访问内存得到数据，根本不会导致多访问磁盘。优化器没有了这一层顾虑，那么它会优先考虑的，就是用于排序的行越小越好了，所以，MySQL 这时就会选择 rowid 排序。 

### 内存临时表

<img src="F:/项目/Git-md/ZJW-Summary/assets/1686934892540.png" alt="1686934892540" style="zoom:67%;" />

 order by rand() 使用了内存临时表，内存临时表排序的时候使用了 rowid 排序方法。 

###  磁盘临时表 

 是不是所有的临时表都是内存表呢？

其实不是的。tmp_table_size 这个配置限制了内存临时表的大小，默认值是 16M。如果临时表大小超过了 tmp_table_size，那么内存临时表就会转成磁盘临时表。 

 磁盘临时表使用的引擎默认是 InnoDB，是由参数 internal_tmp_disk_storage_engine 控制的。

当使用磁盘临时表的时候，对应的就是一个没有显式索引的 InnoDB 表的排序过程。 



 为了复现这个过程，我把 tmp_table_size 设置成 1024，把 sort_buffer_size 设置成 32768, 把 max_length_for_sort_data 设置成 16。 



```
/* 执行语句 */
select word from words order by rand() limit 3;

/* 查看 OPTIMIZER_TRACE 输出 */
SELECT * FROM `information_schema`.`OPTIMIZER_TRACE`\G
```

###  优先队列排序算法

 现在的 SQL 语句，只需要取 R 值最小的 3 个 rowid。但是，如果使用归并排序算法的话，虽然最终也能得到前 3 个值，但是这个算法结束后，已经将 10000 行数据都排好序了。 



### 实际业务处理建议

类似这种 随机取3个单词的情况。

 在实际应用的过程中，比较规范的用法就是：尽量将业务逻辑写在业务代码中，让数据库只做“读写数据”的事情。因此，这类方法的应用还是比较广泛的。 

### 上期问题

 表里面已经有了 city_name(city, name) 这个联合索引 。

 select * from t where city in (“杭州”," 苏州 ") order by name limit 100; 

1、这个 SQL 语句是否需要排序？

 虽然有 (city,name) 联合索引，对于单个 city 内部，name 是递增的。但是由于这条 SQL 语句不是要单独地查一个 city 的值，而是同时查了"杭州"和" 苏州 "两个城市，因此所有满足条件的 name 就不是递增的了。也就是说，这条 SQL 语句需要排序。 



2、有什么方案可以避免排序？ 

 这里，我们要用到 (city,name) 联合索引的特性，把这一条语句拆成两条语句，执行流程如下：

(1) 执行 select * from t where city=“杭州” order by name limit 100; 这个语句是不需要排序的，客户端用一个长度为 100 的内存数组 A 保存结果。

(2) 执行 select * from t where city=“苏州” order by name limit 100; 用相同的方法，假设结果被存进了内存数组 B。

(3) 现在 A 和 B 是两个有序数组，然后你可以用归并排序的思想，得到 name 最小的前 100 值，就是我们需要的结果了。 

# 18 | 为什么这些SQL语句逻辑相同，性能却差异巨大？

函数使用、类型转换、哪怕是表定义的字符格式不同，都会不走索引。

# 19 | 为什么我只查一行的语句，也执行这么慢？

复现技巧： 

先执行了 set long_query_time=0，将慢查询日志的时间阈值设置为 0。 

如果你用的是 MySQL 5.7 版本，可以通过 sys.innodb_lock_waits 表查到。 

```
mysql> select * from t sys.innodb_lock_waits where locked_table='`test`.`t`'\G
```

<img src="F:/项目/Git-md/ZJW-Summary/assets/1686987504400.png" alt="1686987504400" style="zoom:67%;" />



 使用 show processlist 命令查看 Waiting for table metadata lock 的示意图。 

<img src="F:/项目/Git-md/ZJW-Summary/assets/1686987609005.png" alt="1686987609005" style="zoom:80%;" />

 出现这个状态表示的是，现在有一个线程正在表 t 上请求或者持有 MDL 写锁，把 select 语句堵住了。 



全篇目 3个例子： 表锁、行锁和一致性读的概念。 

1、 等 MDL 锁 ， 复现过程是基于 MySQL 5.6 版本的。而 MySQL 5.7 版本修改了 MDL 的加锁策略，所以就不能复现这个场景了。 5.7有别的复现方法。

​	    等 flush (很偏门)

<img src="F:/项目/Git-md/ZJW-Summary/assets/1686987847065.png" alt="1686987847065" style="zoom:80%;" />

 ```
flush tables t with read lock;
flush tables with read lock;
 ```

这两个 flush 语句，如果指定表 t 的话，代表的是只关闭表 t；如果没有指定具体的表名，则表示关闭 MySQL 里所有打开的表。 



2、等行锁，复现就看，图10。

解决： 通过查询 sys.schema_table_lock_waits 这张表，我们就可以直接找出造成阻塞的 process id，把这个连接用 kill 命令断开即可。 

<img src="F:/项目/Git-md/ZJW-Summary/assets/1686987721521.png" alt="1686987721521" style="zoom:67%;" />

3、第一个查询慢是因为查undo log 费事件很多。

第二个查询 lock in share mode 快是因为查的 当前读取。

<img src="F:/项目/Git-md/ZJW-Summary/assets/1686987359037.png" alt="1686987359037" style="zoom:67%;" />

### 上期问题

 表里面，有 100 万行数据，其中有 10 万行数据的 b 的值是’1234567890’， 假设现在执行语句是这么写的: 

```
 mysql> select * from table_a where b='1234567890abcd'; 
结论：因为varchar（10），所以 条件会被自动截断到10，再匹配索引树、回表、再过滤、再为空。

分析：
 最理想的情况是，MySQL 看到字段 b 定义的是 varchar(10)，那肯定返回空呀。可惜，MySQL 并没有这么做。
 
 那要不，就是把’1234567890abcd’拿到索引里面去做匹配，肯定也没能够快速判断出索引树 b 上并没有这个值，也很快就能返回空结果。
 
 但实际上，MySQL 也不是这么做的。这条 SQL 语句的执行很慢。
 流程：
 1、在传给引擎执行的时候，做了字符截断。因为引擎里面这个行只定义了长度是 10，所以只截了前 10 个字节，就是’1234567890’进去做匹配；
 2、这样满足条件的数据有 10 万行；
 3、因为是 select *， 所以要做 10 万次回表；
 4、但是每次回表以后查出整行，到 server 层一判断，b 的值都不是’1234567890abcd’;
 5、返回结果是空。
 
 这个例子，是我们文章内容的一个很好的补充。虽然执行过程中可能经过函数操作，但是最终在拿到结果后，server 层还是要做一轮判断的。
```

# 20 | 幻读是什么，幻读有什么问题？

问题：

首先是语义上的。session A 在 T1 时刻就声明了，“我要把所有 d=5 的行锁住，不准别的事务进行读写操作”。而实际上，这个语义被破坏了。 

其次，是数据一致性的问题。 

幻读过程：

 即使把所有的记录都加上锁，还是阻止不了新插入的记录

解决：

 新插入记录这个动作，要更新的是记录之间的“间隙”。因此，为了解决幻读问题，InnoDB 只好引入新的锁，也就是间隙锁 (Gap Lock)。 

 这样，当你执行 select * from t where d=5 for update 的时候，就不止是给数据库中已有的 6 个记录加上了行锁，还同时加了 7 个间隙锁。这样就确保了无法再插入新的记录。 

锁冲突：

 行锁有冲突关系的是“另外一个行锁”。但是间隙锁不一样，跟间隙锁存在冲突关系的，是“往这个间隙中插入一个记录”这个操作。间隙锁之间都不存在冲突关系。 

 间隙锁和行锁合称 next-key lock，每个 next-key lock 是前开后闭区间。也就是说，我们的表 t 初始化以后，如果用 select * from t for update 要把整个表所有记录锁起来，就形成了 7 个 next-key lock，分别是 (-∞,0]、(0,5]、(5,10]、(10,15]、(15,20]、(20, 25]、(25, +supremum]。 



 间隙锁和 next-key lock 的引入，帮我们解决了幻读的问题，但同时也带来了一些“困扰”。 

### 间隙锁困扰

例子：存在插入，不存在就更新

```
begin;
select * from t where id=N for update;

/*如果行不存在*/
insert into t values(N,N,N);
/*如果行存在*/
update t set d=N set id=N;

commit;
```

并发会死锁，间隙锁不会互斥，但是插入记录的动作会互相等待对方释放间隙锁。

<img src="F:/项目/Git-md/ZJW-Summary/assets/1686993511682.png" alt="1686993511682" style="zoom:67%;" />

产生过程

```
1、session A 执行 select … for update 语句，由于 id=9 这一行并不存在，因此会加上间隙锁 (5,10);
2、session B 执行 select … for update 语句，同样会加上间隙锁 (5,10)，间隙锁之间不会冲突，因此这个语句可以执行成功；
3、session B 试图插入一行 (9,9,9)，被 session A 的间隙锁挡住了，只好进入等待；
4、session A 试图插入一行 (9,9,9)，被 session B 的间隙锁挡住了
```

 至此，两个 session 进入互相等待状态，形成死锁。当然，InnoDB 的死锁检测马上就发现了这对死锁关系，让 session A 的 insert 语句报错返回了。 

 间隙锁的引入，可能会导致同样的语句锁住更大的范围，这其实是影响了并发度的。 

# 21 | 为什么我只改一行的语句，锁这么多？

本篇讲解 加锁的case分析，原则。

 我总结的加锁规则里面，包含了两个“原则”、两个“优化”和一个“bug”。 

```
原则 1：加锁的基本单位是 next-key lock。希望你还记得，next-key lock 是前开后闭区间。
原则 2：查找过程中访问到的对象才会加锁。
优化 1：索引上的等值查询，给唯一索引加锁的时候，next-key lock 退化为行锁。
优化 2：索引上的等值查询，向右遍历时且最后一个值不满足等值条件的时候，next-key lock 退化为间隙锁。一个 bug：唯一索引上的范围查询会访问到不满足条件的第一个值为止。
```

###  案例一：等值查询间隙锁 

```

CREATE TABLE `t` (
  `id` int(11) NOT NULL,
  `c` int(11) DEFAULT NULL,
  `d` int(11) DEFAULT NULL,
  PRIMARY KEY (`id`),
  KEY `c` (`c`)
) ENGINE=InnoDB;

insert into t values
(0,0,0),
(5,5,5),
(10,10,10),
(15,15,15),
(20,20,20),
(25,25,25);
案例6：(30,10,30);
```

<img src="F:/项目/Git-md/ZJW-Summary/assets/1686997216723.png" alt="1686997216723" style="zoom:67%;" />

```
由于表 t 中没有 id=7 的记录，所以用我们上面提到的加锁规则判断一下的话：
1、根据原则 1，加锁单位是 next-key lock，session A 加锁范围就是 (5,10]；
2、同时根据优化 2，这是一个等值查询 (id=7)，而 id=10 不满足查询条件，next-key lock 退化成间隙锁，因此最终加锁的范围是 (5,10)。

所以，session B 要往这个间隙里面插入 id=8 的记录会被锁住，但是 session C 修改 id=10 这行是可以的。 
```

简述：session A 加锁范围 (5,10)，10是被等值优化降级了。

###  案例二：非唯一索引等值锁 

<img src="F:/项目/Git-md/ZJW-Summary/assets/1686997867039.png" alt="1686997867039" style="zoom:67%;" />

简述：

```
看到这个例子，你是不是有一种“该锁的不锁，不该锁的乱锁”的感觉？我们来分析一下吧。

这里 session A 要给索引 c 上 c=5 的这一行加上读锁。

1、根据原则 1，加锁单位是 next-key lock，因此会给 (0,5]加上 next-key lock。
2、要注意 c 是普通索引，因此仅访问 c=5 这一条记录是不能马上停下来的，需要向右遍历，查到 c=10 才放弃。根据原则 2，访问到的都要加锁，因此要给 (5,10]加 next-key lock。
3、但是同时这个符合优化 2：等值判断，向右遍历，最后一个值不满足 c=5 这个等值条件，因此退化成间隙锁 (5,10)。
4、根据原则 2 ，只有访问到的对象才会加锁，这个查询使用覆盖索引，并不需要访问主键索引，所以主键索引上没有加任何锁，这就是为什么 session B 的 update 语句可以执行完成。

但 session C 要插入一个 (7,7,7) 的记录，就会被 session A 的间隙锁 (5,10) 锁住。

需要注意，在这个例子中，lock in share mode 只锁覆盖索引，但是如果是 for update 就不一样了。 执行 for update 时，系统会认为你接下来要更新数据，因此会顺便给主键索引上满足条件的行加上行锁。

这个例子说明，锁是加在索引上的；同时，它给我们的指导是，如果你要用 lock in share mode 来给行加读锁避免数据被更新的话，就必须得绕过覆盖索引的优化，在查询字段中加入索引中不存在的字段。比如，将 session A 的查询语句改成 select d from t where c=5 lock in share mode。你可以自己验证一下效果。
```

简述：普通索引间隙锁会向后蔓延，  where c=5 要到 (5,10），且因为是等值所以向后探寻的10可以变为开区间



lock in share mode 针对where 里面是普通索引（查的是id主键），锁的只是普通索引

而 lock  for update 就会 普通索引、主键索引都锁。

如果你要用 lock in share mode 来给行加读锁避免数据被更新的话，就必须得绕过覆盖索引的优化（原则2），在查询字段中加入索引中不存在的字段（诱导锁上主键索引）。比如，将 session A 的查询语句改成 select d from t where c=5 lock in share mode

### 案例三：主键索引范围锁 

 下面这两条查询语句，加锁范围相同吗？ 其实，它们并不完全等价。  在逻辑上，这两条查语句肯定是等价的，但是它们的加锁规则不太一样。 

```
mysql> select * from t where id=10 for update;
mysql> select * from t where id>=10 and id<11 for update; 
```

分析一下 session A 会加什么锁呢？ 

<img src="F:/项目/Git-md/ZJW-Summary/assets/1686998865015.png" alt="1686998865015" style="zoom:67%;" />

```
1、开始执行的时候，要找到第一个 id=10 的行，因此本该是 next-key lock(5,10]。 根据优化 1， 主键 id 上的等值条件，退化成行锁，只加了 id=10 这一行的行锁。
2、范围查找就往后继续找，找到 id=15 这一行停下来，因此需要加 next-key lock(10,15]。

所以，session A 这时候锁的范围就是主键索引上，行锁 id=10 和 next-key lock(10,15]。这样，session B 和 session C 的结果你就能理解了。

这里你需要注意一点，首次 session A 定位查找 id=10 的行的时候，是当做等值查询来判断的，而向右扫描到 id=15 的时候，用的是范围查询判断。
```

简述：主键的范围只会后探，且会降级。

###  案例四：非唯一索引范围锁 

这是两个范围查询加锁的例子 ，可以对比案例3， 但是 案例四中查询语句的 where 部分用的是字段 c。

<img src="F:/项目/Git-md/ZJW-Summary/assets/1686998944319.png" alt="1686998944319" style="zoom:67%;" />

```
这次 session A 用字段 c 来判断，加锁规则跟案例三唯一的不同是：在第一次用 c=10 定位记录的时候，索引 c 上加了 (5,10]这个 next-key lock 后，由于索引 c 是非唯一索引，没有优化规则，也就是说不会蜕变为行锁。
因此最终 sesion A 加的锁是，索引 c 上的 (5,10] 和 (10,15] 这两个 next-key lock。

所以从结果上来看，sesson B 要插入（8,8,8) 的这个 insert 语句时就被堵住了。

这里需要扫描到 c=15 才停止扫描，是合理的，因为 InnoDB 要扫到 c=15，才知道不需要继续往后找了。
```

简述：非唯一索引间隙锁锁的是他自身，非唯一索引没有行锁，也就没有 间隙锁退化行锁的优化。

疑问：为什么非唯一索引， (5,10] 和 (10,15] 会有前探寻。而唯一索引没有前探寻的  (5,10]  参考案例三，可能主键的特点吧，案例验证的确实没锁。

### 案例五：唯一索引范围锁 bug 

<img src="F:/项目/Git-md/ZJW-Summary/assets/1687000588867.png" alt="1687000588867" style="zoom:67%;" />

```
session A 是一个范围查询，按照原则 1 的话，应该是索引 id 上只加 (10,15]这个 next-key lock，并且因为 id 是唯一键，所以循环判断到 id=15 这一行就应该停止了。

但是实现上，InnoDB 会往前扫描到第一个不满足条件的行为止，也就是 id=20。而且由于这是个范围扫描，因此索引 id 上的 (15,20]这个 next-key lock 也会被锁上。

所以你看到了，session B 要更新 id=20 这一行，是会被锁住的。同样地，session C 要插入 id=16 的一行，也会被锁住。

照理说，这里锁住 id=20 这一行的行为，其实是没有必要的。因为扫描到 id=15，就可以确定不用往后再找了。但实现上还是这么做了，因此我认为这是个 bug。

我也曾找社区的专家讨论过，官方 bug 系统上也有提到，但是并未被 verified。所以，认为这是 bug 这个事儿，也只能算我的一家之言，如果你有其他见解的话，也欢迎你提出来。案例六：非唯一索引上存在"等值"的例子
```

简述：作者认为 session A 是一个范围查询，按照原则 1 的话，应该是索引 id 上只加 (10,15]这个 next-key lock，并且因为 id 是唯一键，所以循环判断到 id=15 这一行就应该停止了。而实际上，锁的范围还下探了。

简述：验证最开始的规则。

###  案例六：非唯一索引上存在"等值"的例子 

加了一行数据：mysql> insert into t values(30,10,30);

<img src="F:/项目/Git-md/ZJW-Summary/assets/1687000798346.png" alt="1687000798346" style="zoom:67%;" />

 用 delete 语句来验证。注意，delete 语句加锁的逻辑，其实跟 select ... for update 是类似的，也就是我在文章开始总结的两个“原则”、两个“优化”和一个“bug”。 

<img src="F:/项目/Git-md/ZJW-Summary/assets/1687001045440.png" alt="1687001045440" style="zoom:67%;" />

```
 这时，session A 在遍历的时候，先访问第一个 c=10 的记录。同样地，根据原则 1，这里加的是 (c=5,id=5) 到 (c=10,id=10) 这个 next-key lock。

然后，session A 向右查找，直到碰到 (c=15,id=15) 这一行，循环才结束。根据优化 2，这是一个等值查询，向右查找到了不满足条件的行，所以会退化成 (c=10,id=10) 到 (c=15,id=15) 的间隙锁。 
```

<img src="F:/项目/Git-md/ZJW-Summary/assets/1687001090502.png" alt="1687001090502" style="zoom:67%;" />

 这个蓝色区域左右两边都是虚线，表示开区间，即 (c=5,id=5) 和 (c=15,id=15) 这两行上都没有锁。 

简述：普通索引两个10，仍然存在间隙，都会被锁。

###  案例七：limit 语句加锁 

<img src="F:/项目/Git-md/ZJW-Summary/assets/1687001121610.png" alt="1687001121610" style="zoom:67%;" />

 表 t 里 c=10 的记录其实只有两条，因此加不加 limit 2，删除的效果都是一样的，但是加锁的效果却不同。 

案例七里的 delete 语句明确加了 limit 2 的限制，因此在遍历到 (c=10, id=30) 这一行之后，满足条件的语句已经有两条，循环就结束了。 

 因此，索引 c 上的加锁范围就变成了从（c=5,id=5) 到（c=10,id=30) 这个前开后闭区间 

<img src="F:/项目/Git-md/ZJW-Summary/assets/1687001279273.png" alt="1687001279273" style="zoom:67%;" />

简述：普通索引where条件，limit可以减少间隙锁的范围，且安全。

指导意义就是，在删除数据的时候尽量加 limit。 

###  案例八：一个死锁的例子 

 目的是说明：next-key lock 实际上是间隙锁和行锁加起来的结果。 

<img src="F:/项目/Git-md/ZJW-Summary/assets/1687001386413.png" alt="1687001386413" style="zoom:67%;" />

```
1、session A 启动事务后执行查询语句加 lock in share mode，在索引 c 上加了 next-key lock(5,10] 和间隙锁 (10,15)；
2、session B 的 update 语句也要在索引 c 上加 next-key lock(5,10] ，进入锁等待；
3、然后 session A 要再插入 (8,8,8) 这一行，被 session B 的间隙锁锁住。由于出现了死锁，InnoDB 让 session B 回滚。
```

 你可能会问，session B 的 next-key lock 不是还没申请成功吗？

其实是这样的，session B 的“加 next-key lock(5,10] ”操作，实际上分成了两步：

1、先是加 (5,10) 的间隙锁，加锁成功；

2、然后加 c=10 的行锁，这时候才被锁住的。

也就是说，我们在分析加锁规则的时候可以用 next-key lock 来分析。

**但是要知道，具体执行的时候，是要分成间隙锁和行锁两段来执行的。** 

### 小结

 next-key lock 实际上是由间隙锁加行锁实现的。

 如果切换到读提交隔离级别 (read-committed) 的话，就好理解了，过程中去掉间隙锁的部分，也就是只剩下行锁的部分。 



**提交读**：

 其实读提交隔离级别在外键场景下还是有间隙锁，相对比较复杂，我们今天先不展开。 

 另外，在读提交隔离级别下还有一个优化，即：语句执行过程中加上的行锁，在语句执行完成后，就要把“不满足条件的行”上的行锁直接释放了，不需要等到事务提交。 

 也就是说，读提交隔离级别下，锁的范围更小，锁的时间更短，这也是不少业务都默认使用读提交隔离级别的原因。

### 问题时间

 为什么 session B 的 insert 语句会被堵住。 

<img src="F:/项目/Git-md/ZJW-Summary/assets/1687008015524.png" alt="1687008015524" style="zoom:67%;" />

  看看 session A 的 select 语句加了哪些锁：

```
1、由于是 order by c desc，第一个要定位的是索引 c 上“最右边的”c=20 的行，所以会加上间隙锁 (20,25) 和 next-key lock (15,20]。
2、在索引 c 上向左遍历，要扫描到 c=10 才停下来，所以 next-key lock 会加到 (5,10]，这正是阻塞 session B 的 insert 语句的原因。
3、在扫描过程中，c=20、c=15、c=10 这三行都存在值，由于是 select *，所以会在主键 id 上加三个行锁。

简述：
因此，session A 的 select 语句锁的范围就是：
1、索引 c 上 (5, 25)；
2、主键索引上 id=15、20 两个行锁。 
```

评论区：

1、 <= 到底是间隙锁还是行锁？

其实，这个问题，你要跟“执行过程”配合起来分析。在 InnoDB 要去找“第一个值”的时候，是按照等值去找的，用的是等值判断的规则；找到第一个值以后，要在索引内找“下一个值”，对应于我们规则中说的范围查找。 

2、如果一个 select * from … for update 语句，优化器决定使用全表扫描，那么就会把主键索引上 next-key lock 全加上。 

 3、“有行”才会加行锁。如果查询条件没有命中行，那就加 next-key lock。当然，等值判断的时候，需要加上优化 2（即：索引上的等值查询，向右遍历时且最后一个值不满足等值条件的时候，next-key lock 退化为间隙锁。）。 

# 22 | MySQL有哪些“饮鸩止渴”提高性能的方法？

###  短连接风暴 

 max_connections 参数，不可太大，失去对mysql的保护，太小 “Too many connections” 。

处理：

 第一种方法：先处理掉那些占着连接但是不工作的线程。 

 show processlist  踢掉显示为 sleep 的线程， 可能是有损的 

<img src="F:/项目/Git-md/ZJW-Summary/assets/1687007440545.png" alt="1687007440545" style="zoom:67%;" />

查看事务状况： information_schema 库的 innodb_trx 表。 

<img src="F:/项目/Git-md/ZJW-Summary/assets/1687007427037.png" alt="1687007427037" style="zoom:67%;" />

 因此，如果是连接数过多，你可以优先断开事务外空闲太久的连接；如果这样还不够，再考虑断开事务内空闲太久的连接。 



 第二种方法：减少连接过程的消耗。 

 有的业务代码会在短时间内先大量申请数据库连接做备用，如果现在数据库确认是被连接行为打挂了，那么一种可能的做法，是让数据库跳过权限验证阶段。  “饮鸩止渴”，风险极高，是我特别不建议使用的方案。 

###  慢查询性能问题 

1、 索引没有设计好；2、SQL 语句没写好；3、MySQL 选错了索引。 

# 23 | MySQL是怎么保证数据不丢的？

 日志逻辑序列号（log sequence number，LSN）的概念。

LSN 是单调递增的，用来对应 redo log 的一个个写入点。每次写入长度为 length 的 redo log， LSN 的值就会加上 length。 

###  binlog 的写入机制 

###  redo log 的写入机制 



### 双1配置

 通常我们说 MySQL 的“双 1”配置，指的就是 sync_binlog 和 innodb_flush_log_at_trx_commit 都设置成 1。也就是说，一个事务完整提交前，需要等待两次刷盘，一次是 redo log（prepare 阶段），一次是 binlog。 



有组提交机制，多个 redo log buffer  到  page cache  可以通过频控来进行处理。比如几个事务 处理一次、多少时间间隔后处理一次。

其他 处理时机：

1、 redo log buffer 占用的空间即将达到 innodb_log_buffer_size 一半的时候，后台线程主动写盘。

2、 另一种是，并行的事务提交的时候，顺带将这个事务的 redo log buffer 持久化到磁盘。 



问：WAL 机制是减少磁盘写，可是每次提交事务都要写 redo log 和 binlog，这磁盘读写次数也没变少呀？ 

答：WAL 机制主要得益于两个方面：

1、redo log 和 binlog 都是顺序写，磁盘的顺序写比随机写速度要快；

2、组提交机制，可以大幅度降低磁盘的 IOPS 消耗。 



### MySQL 性能瓶颈在 IO 上怎么处理?

```
1、设置 binlog_group_commit_sync_delay 和 binlog_group_commit_sync_no_delay_count 参数，减少 binlog 的写盘次数。这个方法是基于“额外的故意等待”来实现的，因此可能会增加语句的响应时间，但没有丢失数据的风险。
2、将 sync_binlog 设置为大于 1 的值（比较常见是 100~1000）。这样做的风险是，主机掉电时会丢 binlog 日志。
3、将 innodb_flush_log_at_trx_commit 设置为 2。这样做的风险是，主机掉电的时候会丢数据。
```

 我不建议你把 innodb_flush_log_at_trx_commit 设置成 0。因为把这个参数设置成 0，表示 redo log 只保存在内存中，这样的话 MySQL 本身异常重启也会丢数据，风险太大。而 redo log 写到文件系统的 page cache 的速度也是很快的，所以将这个参数设置成 2 跟设置成 0 其实性能差不多，但这样做 MySQL 异常重启时就不会丢数据了，相比之下风险会更小。 

### 上期问题

线上救火经历：

 “如果一个数据库是被客户端的压力打满导致无法响应的，重启数据库是没用的。”，说明他很好地思考了。这个问题是因为重启之后，业务请求还会再发。而且由于是重启，buffer pool 被清空，可能会导致语句执行得更慢。 

# 24 | MySQL是怎么保证主备一致的？

###  MySQL 主备的基本原理 

依赖binlog以及 同步后是 relay log 中转日志的解析，后续这个解析已经是多线程了。

###  binlog 的三种格式对比 

statement、 row 、mixed

```
执行Sql测试
mysql> delete from t /*comment*/  where a>=4 and t_modified<='2018-11-10' limit 1;

关键是 limit 1 不好区分。造成了多种可能性。
```

日志简单查看

mysql> show binlog events in 'master.000001';

<img src="F:/项目/Git-md/ZJW-Summary/assets/b9818f73cd7d38a96ddcb75350b52931.png" alt="img" style="zoom:67%;" /> 

 当 binlog_format=statement 时，binlog 里面记录的就是 SQL 语句的原文。 

 由于 statement 格式下，记录到 binlog 里的是语句原文，因此可能会出现这样一种情况：在主库执行这条 SQL 语句的时候，用的是索引 a；而在备库执行这条 SQL 语句的时候，却使用了索引 t_modified。因此，MySQL 认为这样写是有风险的。 



 当 binlog_format=row  时

 row 格式的 binlog 里没有了 SQL 语句的原文，而是替换成了两个 event：Table_map 和 Delete_rows。

1、Table_map event，用于说明接下来要操作的表是 test 库的表 t;

2、Delete_rows event，用于定义删除的行为。 

 当 binlog_format 使用 row 格式的时候，binlog 里面记录了真实删除行的主键 id，这样 binlog 传到备库去的时候，就肯定会删除 id=4 的行，不会有主备删除不同行的问题。 

###  为什么会有 mixed 格式的 binlog？ 

1、 因为有些 statement 格式的 binlog 可能会导致主备不一致，所以要使用 row 格式。 

2、 但 row 格式的缺点是，很占空间。  比如你用一个 delete 语句删掉 10 万行数据，用 statement 的话就是一个 SQL 语句被记录到 binlog 中，占用几十个字节的空间。  row 格式的 binlog，就要把这 10 万条记录都写到 binlog 中 。

所以 mixed 就是一个 折中的方案，mysql自己判断选取。纯statement 不建议，至少是mixed。



 现在越来越多的场景要求把 MySQL 的 binlog 格式设置成 row。这么做的理由有很多，我来给你举一个可以直接看出来的好处：**恢复数据。** 

原因：

即使我执行的是 delete 语句，row 格式的 binlog 也会把被删掉的行的整行信息保存起来。所以，如果你在执行完一条 delete 语句以后，发现删错数据了，可以直接把 binlog 中记录的 delete 语句转成 insert，把被错删的数据插入回去就可以恢复了。 

插入转删除也是可以的。update会记录前后的变更，可以把两个对调进行恢复。

### 数据恢复误区

 错误操作：

我之前看过有人在重放 binlog 数据的时候，是这么做的：用 mysqlbinlog 解析出日志，然后把里面的 statement 语句直接拷贝出来执行。

你现在知道了，这个方法是有风险的。因为有些语句的执行结果是依赖于上下文命令的，直接执行的结果很可能是错误的。 

正确操作：

 用 binlog 来恢复数据的标准做法是，用 mysqlbinlog 工具解析出来，然后把解析结果整个发给 MySQL 执行。 

###  循环复制问题 

<img src="F:/项目/Git-md/ZJW-Summary/assets/1687016001342.png" alt="1687016001342" style="zoom:67%;" />

双M结构下，A、B的binlog互相同步死循环，就是循环复制的问题。

解决：

binlog带上自己的server id



### 上期问题

 什么时候会把线上生产库设置成“非双 1”？

1、 业务高峰期。一般如果有预知的高峰期，DBA 会有预案，把主库设置成“非双 1”。

2、备库延迟，为了让备库尽快赶上主库。@永恒记忆和 @Second Sight 提到了这个场景。

3、用备份恢复主库的副本，应用 binlog 的过程，这个跟上一种场景类似。

4、批量导入数据的时候。

一般情况下，把生产库改成“非双 1”配置，是设置 innodb_flush_logs_at_trx_commit=2、sync_binlog=1000。 

# 25 | MySQL是怎么保证高可用的？

###  主备延迟 

1、主库 A 执行完成一个事务，写入 binlog，我们把这个时刻记为 T1;

2、之后传给备库 B，我们把备库 B 接收完这个 binlog 的时刻记为 T2;

3、备库 B 执行完成这个事务，我们把这个时刻记为 T3。 

计算为 T3 - T2，实际上T2 到T1很短一般。



原因简述

1、首先，有些部署条件下，备库所在机器的性能要比主库所在的机器性能差。 

当下流行部署：

 因为主备可能发生切换，备库随时可能变成主库，所以主备库选用相同规格的机器，并且做对称部署，是现在比较常见的情况。 历史不友好部署： 他们会把 20 个主库放在 4 台机器上，而把备库集中在一台机器上。 

2、备库查询压力大

3、大事务



讲了主从切换逻辑：

 可靠性优先和可用性优先策略的区别 ，没细看。

### 上期问题

 什么情况下双 M 结构会出现循环复制。 



 一种场景是，在一个主库更新事务后，用命令 set global server_id=x 修改了 server_id。等日志再传回来的时候，发现 server_id 跟自己的 server_id 不同，就只能执行了。 



 另一种场景是，有三个节点的时候，如图 7 所示，trx1 是在节点 B 执行的，因此 binlog 上的 server_id 就是 B，binlog 传给节点 A，然后 A 和 A’搭建了双 M 结构，就会出现循环复制。 

<img src="F:/项目/Git-md/ZJW-Summary/assets/1687017403420.png" alt="1687017403420" style="zoom:67%;" />

解决方法：IGNORE_SERVER_IDS 、或者 来回切换节点等等。。

# 26 | 备库为什么会延迟好几个小时？

实际上备库消费的速度要必须大于生产速度的，否则延迟只会越来越大。

 备库并行复制能力。 



###  MySQL 5.5 版本的并行复制策略 

####  按表分发策略 

####  按行分发策略 

 相比于按表并行分发策略，按行并行策略在决定线程分发的时候，需要消耗更多的计算资源。 

###  MySQL 5.6 版本的并行复制策略 

###  MariaDB 的并行复制策略 

###  MySQL 5.7 的并行复制策略 

###  MySQL 5.7.22 的并行复制策略 

 相应地，新增了一个参数 binlog-transaction-dependency-tracking，用来控制是否启用这个新策略。 

# 27 | 主库出问题了，从库怎么办？

 介绍了一主多从的主备切换流程。在这个过程中，从库找新主库的位点是一个痛点。由此，我们引出了 MySQL 5.6 版本引入的 GTID 模式，介绍了 GTID 的基本概念和用法。  可以看到，在 GTID 模式下，一主多从切换就非常方便了。 

### 上期问题

 如果主库都是单线程压力模式，在从库追主库的过程中，binlog-transaction-dependency-tracking 应该选用什么参数？  这个问题的答案是，应该将这个参数设置为 WRITESET。 

 由于主库是单线程压力模式，所以每个事务的 commit_id 都不同，那么设置为 COMMIT_ORDER 模式的话，从库也只能单线程执行。

同样地，由于 WRITESET_SESSION 模式要求在备库应用日志的时候，同一个线程的日志必须与主库上执行的先后顺序相同，也会导致主库单线程压力模式下退化成单线程复制。

所以，应该将 binlog-transaction-dependency-tracking 设置为 WRITESET。 

# 28 | 读写分离有哪些坑？

 聊聊一主多从架构的应用场景：读写分离，以及怎么处理主备延迟导致的读写分离问题。 

### 读写分离架构

<img src="F:/项目/Git-md/ZJW-Summary/assets/1687072708212.png" alt="1687072708212" style="zoom:67%;" />

第一种：客户端（client）主动做负载均衡，这种模式下一般会把数据库的连接信息放在客户端的连接层。也就是说，由客户端来选择后端数据库进行查询。 

<img src="F:/项目/Git-md/ZJW-Summary/assets/1687072719716.png" alt="1687072719716" style="zoom:67%;" />

 处理过期读的方案汇总（处理主从延迟）

```
强制走主库方案；
sleep 方案；
判断主备无延迟方案；   不懂了
配合 semi-sync 方案；不懂了
等主库位点方案；	  不懂了
等 GTID 方案。		 不懂了
```

个人理解：根据业务情况选择强制主库。

# 29 | 如何判断一个数据库是不是出问题了？

 介绍了检测一个 MySQL 实例健康状态的几种方法 。

 select 1 不靠谱的点在于， 只能说明这个库的进程还在，并不能说明主库没问题。 

 虽然说等锁的线程不算在并发线程计数里，但如果它在真正地执行查询，就比如我们上面例子中前三个事务中的 select sleep(100) from t，还是要算进并发线程的计数的。 

 在这个例子中，同时在执行的语句超过了设置的 innodb_thread_concurrency 的值，这时候系统其实已经不行了，但是通过 select 1 来检测系统，会认为系统还是正常的。 



 我个人比较倾向的方案，是优先考虑 update 系统表，然后再配合增加检测 performance_schema 的信息。 

# 30 | 答疑文章（二）：用动态的观点看加锁

针对20、21篇目的加锁相关的答疑。

```
CREATE TABLE `t` (
  `id` int(11) NOT NULL,
  `c` int(11) DEFAULT NULL,
  `d` int(11) DEFAULT NULL,
  PRIMARY KEY (`id`),
  KEY `c` (`c`)
) ENGINE=InnoDB;

insert into t values(0,0,0),(5,5,5),
(10,10,10),(15,15,15),(20,20,20),(25,25,25);
```

###  不等号条件里的等值查询 

```
begin;
select * from t where id>9 and id<12 order by id desc for update;
```

 这个语句的加锁范围是主键索引上的 (0,5]、(5,10]和 (10, 15)。也就是说，id=15 这一行，并没有被加上行锁。

 查询语句中 where 条件是大于号和小于号，这里的“等值查询”又是从哪里来的呢？ 

<img src="F:/项目/Git-md/ZJW-Summary/assets/1687074966059.png" alt="1687074966059" style="zoom:67%;" />

```
1、首先这个查询语句的语义是 order by id desc，要拿到满足条件的所有行，优化器必须先找到“第一个 id<12 的值”。这个过程是通过索引树的搜索过程得到的，在引擎内部，其实是要找到 id=12 的这个值，只是最终没找到，但找到了 (10,15) 这个间隙。
2、然后向左遍历，在遍历过程中，就不是等值查询了，会扫描到 id=5 这一行，所以会加一个 next-key lock (0,5]。

也就是说，在执行过程中，通过树搜索的方式定位记录的时候，用的是“等值查询”的方法。
```

###  等值查询的过程 

语句1：

```
begin;
select id from t where c in(5,20,10) lock in share mode;
```

<img src="F:/项目/Git-md/ZJW-Summary/assets/1687076266039.png" alt="1687076266039" style="zoom:80%;" />

```
可以看到，这条 in 语句使用了索引 c 并且 rows=3，说明这三个值都是通过 B+ 树搜索定位的。

1、在查找 c=5 的时候，先锁住了 (0,5]。但是因为 c 不是唯一索引，为了确认还有没有别的记录 c=5，就要向右遍历，找到 c=10 才确认没有了，这个过程满足优化 2，所以加了间隙锁 (5,10)。

2、同样的，执行 c=10 这个逻辑的时候，加锁的范围是 (5,10] 和 (10,15)；执行 c=20 这个逻辑的时候，加锁的范围是 (15,20] 和 (20,25)。

通过这个分析，我们可以知道，这条语句在索引 c 上加的三个记录锁的顺序是：先加 c=5 的记录锁，再加 c=10 的记录锁，最后加 c=20 的记录锁。 
```

语句2：

```
select id from t where c in(5,20,10) order by c desc for update;
```

 由于语句里面是 order by c desc， 这三个记录锁的加锁顺序，是先锁 c=20，然后 c=10，最后是 c=5。 

也就是说，这两条语句要加锁相同的资源，但是加锁顺序相反。当这两条语句并发执行的时候，就可能出现死锁。 

### 死锁排查

 图 3 是在出现死锁后，执行 show engine innodb status 命令得到的部分输出。这个命令会输出很多信息，有一节 LATESTDETECTED DEADLOCK，就是记录的最后一次死锁信息。 

<img src="F:/项目/Git-md/ZJW-Summary/assets/1687076351281.png" alt="1687076351281" style="zoom:80%;" />

 从上面这些信息中（具体看作者对页面的日志分析吧，很多），我们就知道：

“lock in share mode”的这条语句，持有 c=5 的记录锁，在等 c=10 的锁；

“for update”这个语句，持有 c=20 和 c=10 的记录锁，在等 c=5 的记录锁。 

```
因此导致了死锁。这里，我们可以得到两个结论：
1、由于锁是一个个加的，要避免死锁，对同一组资源，要按照尽量相同的顺序访问；
2、在发生死锁的时刻，for update 这条语句占有的资源更多，回滚成本更大，所以 InnoDB 选择了回滚成本更小的 lock in share mode 语句，来回滚。
```

###  锁等待	

<img src="F:/项目/Git-md/ZJW-Summary/assets/1687076562985.png" alt="1687076562985" style="zoom:67%;" />

 show engine innodb status 的结果，看不懂、解释不懂。

因此：由于 delete 操作把 id=10 这一行删掉了，原来的两个**间隙** (5,10)、(10,15）变成了一个 (5,15)。 

评论补充：实际上在删除之前间隙锁只有一个(10, 15)，删除了数据之后，导致间隙锁左侧扩张成了5，间隙锁成为了(5, 15)。 

```
思考一下这两个现象之间的关联：
1、session A 执行完 select 语句后，什么都没做，但它加锁的范围突然“变大”了；
2、第 21 篇文章的课后思考题，当我们执行 select * from t where c>=15 and c<=20 order by c desc lock in share mode; 向左扫描到 c=10 的时候，要把 (5, 10]锁起来。

也就是说，所谓“间隙”，其实根本就是由“这个间隙右边的那个记录”定义的。
```

简述：删除数据行，导致别的事务的锁范围自然变大。

### update 的例子 

<img src="F:/项目/Git-md/ZJW-Summary/assets/1687077664118.png" alt="1687077664118" style="zoom:67%;" />

 session A 的加锁范围是索引 c 上的 (5,10]、(10,15]、(15,20]、(20,25]和 (25,supremum]。 

注意：根据 c>5 查到的第一个记录是 c=10，因此不会加 (0,5]这个 next-key lock。



之后 session B 的第一个 update 语句，要把 c=5 改成 c=1，你可以理解为两步：

1、插入 (c=1, id=5) 这个记录；

2、删除 (c=5, id=5) 这个记录。 



按照我们上一节说的，索引 c 上 (5,10) 间隙是由这个间隙右边的记录，也就是 c=10 定义的。所以通过这个操作，session A 的加锁范围变成了图 7 所示的样子：

<img src="F:/项目/Git-md/ZJW-Summary/assets/1687080823542.png" alt="1687080823542" style="zoom:67%;" />

 好，接下来 session B 要执行 update t set c = 5 where c = 1 这个语句了，一样地可以拆成两步：

1、插入 (c=5, id=5) 这个记录；

2、删除 (c=1, id=5) 这个记录。 

第一步试图在已经加了间隙锁的 (1,10) 中插入数据，所以就被堵住了。

简述：update可以看做是先插入后删除，next-lock以（查到的）右侧数据 向左辐射为准， 5被变为1 后，就是 从10 辐射到1 了，无形锁范围变大了。

### 评论区

锁日志的理解

 lock_mode X waiting表示next-key lock；

 lock_mode X locks rec but not gap是只有行锁； 

还有一种 “locks gap before rec”，就是只有间隙锁； 



老师，之前讲这个例子时，select * from t where c>=15 and c<=20 order by c desc in share mode; 最右边加的是 (20, 25)的间隙锁， 而这个例子select * from t where id>10 and id<=15 for update中，最右边加的是(15,20]的next-key锁， 这两个查询为何最后边一个加的gap锁，一个加的next-key锁，他们都是<=的等值范围查询，区别在哪里？ 

```
作者回复: select * from t where c>=15 and c<=20 order by c desc in share mode;

这个语句是根据 c=20 来查数据的，所以加锁(20,25]的时候，可以使用优化2；

select * from t where id>10 and id<=15 for update；
这里的id=20，是用“向右遍历”的方式得到的，没有优化，按照“以next-key lock”为加锁单位来执行
```

# 31 | 误删数据后除了跑路，还能怎么办？

###  误删行 

 Flashback 恢复数据的原理，是修改 binlog 的内容，拿回原库重放。而能够使用这个方案的前提是，需要确保 binlog_format=row 和 binlog_row_image=FULL。 

###  误删库 / 表 

 需要使用全量备份，加增量日志的方式了 

###  rm 删除数据 

 选出一个新的主库，从而保证整个集群的正常工作。 

### 小结

预防比处理更重要。



###  上期问题

空表有无间隙？

 一个空表就只有一个间隙。比如，在空表上执行： 

select * from t where id>1 for update; 

 这个查询语句加锁的范围就是 next-key lock (-∞, supremum]。 

<img src="F:/项目/Git-md/ZJW-Summary/assets/1687083028696.png" alt="1687083028696" style="zoom:67%;" />

# 32 | 为什么还有kill不掉的语句？

### 小结

 这些“kill 不掉”的情况，其实是因为发送 kill 命令的客户端，并没有强行停止目标线程的执行，而只是设置了个状态，并唤醒对应的线程。而被 kill 的线程，需要执行到判断状态的“埋点”，才会开始进入终止逻辑阶段。并且，终止逻辑本身也是需要耗费时间的。

所以，如果你发现一个线程处于 Killed 状态，你可以做的事情就是，通过影响系统环境，让这个 Killed 状态尽快结束。 

# 33 | 我查这么多数据，会不会把数据库内存打爆？

###  全表扫描对 server 层的影响 

 MySQL 是“边读边发的”，这个概念很重要。这就意味着，如果客户端接收得慢，会导致 MySQL 服务端由于结果发不出去，这个事务的执行时间变长。 

 查询的结果是分段发给客户端的，因此扫描全表，查询返回大量的数据，并不会把内存打爆。 

###  全表扫描对 InnoDB 的影响 



### 小结

 由于 MySQL 采用的是边算边发的逻辑，因此对于数据量很大的查询结果来说，不会在 server 端保存完整的结果集。所以，如果客户端读结果不及时，会堵住 MySQL 的查询过程，但是不会把内存打爆。 

 对于 InnoDB 引擎内部，由于有淘汰策略，大查询也不会导致内存暴涨。并且，由于 InnoDB 对 LRU 算法做了改进，冷数据的全表扫描，对 Buffer Pool 的影响也能做到可控。 

 全表扫描还是比较耗费 IO 资源的，所以业务高峰期还是不能直接在线上主库执行全表扫描的。 

# 34 | 到底可不可以使用join？

###  Index Nested-Loop Join 

 select * from t1 straight_join t2 on (t1.a=t2.a);

这个过程是先遍历表 t1，然后根据从表 t1 中取出的每行数据中的 a 值，去表 t2 中查找满足条件的记录。在形式上，这个过程就跟我们写程序时的嵌套查询类似，并且可以用上被驱动表的索引，所以我们称之为“Index Nested-Loop Join”，简称 NLJ。 



 能不能使用 join? 

 单表查询，比直接 join 多了 100 次交互。除此之外，客户端还要自己拼接 SQL 语句和结果。 

 显然，这么做还不如直接 join 好。 



 怎么选择驱动表？ 

 join 语句执行过程中，驱动表是走全表扫描，而被驱动表是走树搜索。 

结论：

1、 使用 join 语句，性能比强行拆成多个单表执行 SQL 语句的性能要好； 

2、 如果使用 join 语句的话，需要让小表做驱动表。 （大表做内嵌套表也就是被驱动表，可以用到索引）

###  Simple Nested-Loop Join 

 select * from t1 straight_join t2 on (t1.a=t2.b);

由于表 t2 的字段 b 上没有索引，因此再用图 2 的执行流程时，每次到 t2 去匹配的时候，就要做一次全表扫描。 

###  Block Nested-Loop Join 

 这时候，被驱动表上没有可用的索引。

 结论是，应该让小表当驱动表。 





 第一个问题：能不能使用 join 语句？

1、如果可以使用 Index Nested-Loop Join 算法，也就是说可以用上被驱动表上的索引，其实是没问题的；

2、如果使用 Block Nested-Loop Join 算法，扫描行数就会过多。尤其是在大表上的 join 操作，这样可能要扫描被驱动表很多次，会占用大量的系统资源。所以这种 join 尽量不要用。

所以你在判断要不要使用 join 语句时，就是看 explain 结果里面，Extra 字段里面有没有出现“Block Nested Loop”字样。 

 第二个问题是：如果要使用 join，应该选择大表做驱动表还是选择小表做驱动表？

1、如果是 Index Nested-Loop Join 算法，应该选择小表做驱动表；

2、如果是 Block Nested-Loop Join 算法：

​	在 join_buffer_size 足够大的时候，是一样的；

​	在 join_buffer_size 不够大的时候（这种情况更常见），应该选择小表做驱动表。

所以，这个问题的结论就是，**总是应该使用小表做驱动表**。 



 什么叫作“小表”？

 在决定哪个表做驱动表的时候，应该是两个表按照各自的条件过滤，过滤完成之后，计算参与 join 的各个字段的总数据量，数据量小的那个表，就是“小表”，应该作为驱动表。 

# 35 | join语句怎么优化？

###  Multi-Range Read 优化 

 因为大多数的数据都是按照主键递增顺序插入得到的，所以我们可以认为，如果按照主键的递增顺序查询的话，对磁盘的读比较接近顺序读，能够提升读性能。 

 MRR 能够提升性能的核心在于，这条查询语句在索引 a 上做的是一个范围查询（也就是说，这是一个多值查询），可以得到足够多的主键 id。这样通过排序以后，再去主键索引查数据，才能体现出“顺序性”的优势。 

###  Batched Key Access 

###  BNL 算法的性能问题 

 大表 join 操作虽然对 IO 有影响，但是在语句执行结束后，对 IO 的影响也就结束了。但是，对 Buffer Pool 的影响就是持续性的，需要依靠后续的查询请求慢慢恢复内存命中率。 

 为了减少这种影响，你可以考虑增大 join_buffer_size 的值，减少对被驱动表的扫描次数。 

###  BNL 转 BKA 

 总体来看，不论是在原表上加索引，还是用有索引的临时表，我们的思路都是让 join 语句能够用上被驱动表上的索引，来触发 BKA 算法，提升查询性能。 

###  扩展 -hash join 

。。。mysql目前不支持

### 小结

 BKA 优化是 MySQL 已经内置支持的，建议你默认使用；

BNL 算法效率低，建议你都尽量转成 BKA 算法。优化的方向就是给被驱动表的关联字段加上索引；

基于临时表的改进方案，对于能够提前过滤出小数据的 join 语句来说，效果还是很好的；

MySQL 目前的版本还不支持 hash join，但你可以配合应用端自己模拟出来，理论上效果要好于临时表的方案。 

# 36 | 为什么临时表可以重名？

###  临时表的特性 

1、 建表语法是 create temporary table …。

2、一个临时表只能被创建它的 session 访问，对其他线程不可见。所以，图中 session A 创建的临时表 t，对于 session B 就是不可见的。

3、临时表可以与普通表同名。

4、session A 内有同名的临时表和普通表的时候，show create 语句，以及增删改查语句访问的是临时表。

5、show tables 命令不显示临时表。 

 由于临时表只能被创建它的 session 访问，所以在这个 session 结束的时候，会自动删除临时表。也正是由于这个特性，临时表就特别适合我们文章开头的 join 优化这种场景。 

###  临时表的应用 

 由于不用担心线程之间的重名冲突，临时表经常会被用在复杂查询的优化过程中。其中，分库分表系统的跨库查询就是一个典型的使用场景。 



 为什么临时表可以重名？ 

我猜的，线程维度的

### 小结

 在实际应用中，临时表一般用于处理比较复杂的计算逻辑。由于临时表是每个线程自己可见的，所以不需要考虑多个线程执行同一个处理逻辑时，临时表的重名问题。在线程退出的时候，临时表也能自动删除，省去了收尾和异常处理的工作。 

# 37 | 什么时候会使用内部临时表？

###  union 执行流程 

###  group by 执行流程 

 Using index，表示这个语句使用了覆盖索引，选择了索引 a，不需要回表；

Using temporary，表示使用了临时表；

Using filesort，表示需要排序。 

###  group by 优化方法 -- 直接排序 

 从 Extra 字段可以看到，这个语句的执行没有再使用临时表，而是直接用了排序算法。



基于上面的 union、union all 和 group by 语句的执行过程的分析，我们来回答文章开头的问题：MySQL 什么时候会使用内部临时表？

1、如果语句执行过程可以一边读数据，一边直接得到结果，是不需要额外内存的，否则就需要额外的内存，来保存中间结果；

2、join_buffer 是无序数组，sort_buffer 是有序数组，临时表是二维表结构；

3、如果执行逻辑需要用到二维表特性，就会优先考虑使用临时表。比如我们的例子中，union 需要用到唯一索引约束， group by 还需要用到另外一个字段来存累积计数。 

### 小结

 重点和你讲了 group by 的几种实现算法 

1、 如果对 group by 语句的结果没有排序要求，要在语句后面加 order by null；

2、尽量让 group by 过程用上表的索引，确认方法是 explain 结果里没有 Using temporary 和 Using filesort；

3、如果 group by 需要统计的数据量不大，尽量只使用内存临时表；也可以通过适当调大 tmp_table_size 参数，来避免用到磁盘临时表；

4、如果数据量实在太大，使用 SQL_BIG_RESULT 这个提示，来告诉优化器直接使用排序算法得到 group by 的结果。 

# 38 | 都说InnoDB好，那还要不要使用Memory引擎？

```
create table t1(id int primary key, c int) engine=Memory;
create table t2(id int primary key, c int) engine=innodb;
insert into t1 values(1,1),(2,2),(3,3),(4,4),(5,5),(6,6),(7,7),(8,8),(9,9),(0,0);
insert into t2 values(1,1),(2,2),(3,3),(4,4),(5,5),(6,6),(7,7),(8,8),(9,9),(0,0);
```

<img src="F:/项目/Git-md/ZJW-Summary/assets/1687086219856.png" alt="1687086219856" style="zoom:67%;" />

### 内存表的数据组织结构 

<img src="F:/项目/Git-md/ZJW-Summary/assets/1687085911906.png" alt="1687085911906" style="zoom:67%;" />

 与 InnoDB 引擎不同，Memory 引擎的数据和索引是分开的 

 内存表的数据部分以数组的方式单独存放，而主键 id 索引里，存的是每个数据的位置。主键 id 是 hash 索引，可以看到索引上的 key 并不是有序的。 



###  InnoDB 和 Memory 引擎的数据组织方式的区别

- InnoDB 引擎把数据放在主键索引上，其他索引上保存的是主键 id。这种方式，我们称之为索引组织表（Index Organizied Table）。

- 而 Memory 引擎采用的是把数据单独存放，索引上保存数据位置的数据组织形式，我们称之为堆组织表（Heap Organizied Table）。 

### 两引擎的典型不同

1、 InnoDB 表的数据总是有序存放的，而内存表的数据就是按照写入顺序存放的；

2、当数据文件有空洞的时候，InnoDB 表在插入新数据的时候，为了保证数据有序性，只能在固定的位置写入新值，而内存表找到空位就可以插入新值；

3、数据位置发生变化的时候，InnoDB 表只需要修改主键索引，而内存表需要修改所有索引；

4、InnoDB 表用主键索引查询时需要走一次索引查找，用普通索引查询的时候，需要走两次索引查找。而内存表没有这个区别，所有索引的“地位”都是相同的。

5、InnoDB 支持变长数据类型，不同记录的长度可能不同；内存表不支持 Blob 和 Text 字段，并且即使定义了 varchar(N)，实际也当作 char(N)，也就是固定长度字符串来存储，因此内存表的每行数据长度相同。 



### 区别简述

1、索引上，innodb 有主键、非主键 索引的区别，内存表索引都一样对等

2、数据存放顺序上，innodb 总是有序，内存表无序。

3、数据的插入，innodb 找到固定位置，内存表找空洞位置即可

4、数据位置变更，innodb 只改主键索引，内存表改所有索引

5、数据存储类型，innodb 支持根据实际空间变长数据类型varchar，内存表都是固定长度。

如果 内存表的 主键索引就是哈希索引，范围查询就是全表查询。

内存表不支持行锁，只有表锁。 更新语句会阻塞查询。

内存 表数据放在内存，速度快，但是数据 持久性不好，重启会清空内存。

###  hash 索引和 B-Tree 索引 

 内存表也是支持 B-Tree 索引的。

```
alter table t1 add index a_btree_index using btree (id);
```

<img src="F:/项目/Git-md/ZJW-Summary/assets/1687086698595.png" alt="1687086698595" style="zoom:67%;" />

 一般在我们的印象中，内存表的优势是速度快，其中的一个原因就是 Memory 引擎支持 hash 索引。当然，更重要的原因是，内存表的所有数据都保存在内存，而内存的读写速度总是比磁盘快。 

### 不建议内存引擎的原因

 锁粒度问题、数据持久化问题。 

###  内存表的锁 

 内存表不支持行锁，只支持表锁 

###  数据持久性问题 

 数据放在内存中，是内存表的优势，但也是一个劣势。因为，数据库重启的时候，所有的内存表都会被清空。 

# 39 | 自增主键为什么不是连续的？

###  自增值保存在哪儿？ 

 自增值是保存在表结构定义里的。实际上，表的结构定义存放在后缀名为.frm 的文件中，但是并不会保存自增值。 

 不同的引擎对于自增值的保存策略不同。 

- MyISAM 引擎的自增值保存在数据文件中。 

-  InnoDB 引擎的自增值，其实是保存在了内存里，重启后找最大的+1现算的，而到了 MySQL 8.0 版本后存放在redo log里面。

###  自增主键 id 不能保证是连续的原因

1、 可见，唯一键冲突是导致自增主键 id 不连续的第一种原因。 

2、 事务回滚也会产生类似的现象，这就是第二种原因。 

可以保证递增，但是不保证连续。

3、 批量插入数据的语句，“不知道要预先申请多少个 id” 

 深层次原因是，**不判断自增主键是否已存在**和**减少加锁的时间范围和粒度-**>为了更高的性能->自增主键不能回退->自增主键不连续 

# 40 | insert语句的锁为什么这么多？

 介绍了几种特殊情况下的 insert 语句。 

### 小结

 insert … select 是很常见的在两个表之间拷贝数据的方法。你需要注意，在可重复读隔离级别下，这个语句会给 select 的表里扫描到的记录和间隙加读锁。 

 而如果 insert 和 select 的对象是同一个表，则有可能会造成循环写入。这种情况下，我们需要引入用户临时表来做优化。 

 insert 语句如果出现唯一键冲突，会在冲突的唯一值上加共享的 next-key lock(S 锁)。因此，碰到由于唯一键约束导致报错后，要尽快提交或回滚事务，避免加锁时间过长。 

# 41 | 怎么最快地复制一张表？

###  mysqldump 方法 

导出insert语句。

mysqldump -h$host -P$port -u$user --add-locks=0 --no-create-info --single-transaction  --set-gtid-purged=OFF db1 t --where="a>900" --result-file=/client_tmp/t.sql

###  导出 CSV 文件 

select * from db1.t where a>900 into outfile '/server_tmp/t.csv';

再导入

load data infile '/server_tmp/t.csv' into table db2.t;

###  物理拷贝方法 

### 小结

 这三种方法的优缺点。

1、物理拷贝的方式速度最快，尤其对于大表拷贝来说是最快的方法。如果出现误删表的情况，用备份恢复出误删之前的临时库，然后再把临时库中的表拷贝到生产库上，是恢复数据最快的方法。但是，这种方法的使用也有一定的局限性：

​	必须是全表拷贝，不能只拷贝部分数据；	

​	需要到服务器上拷贝数据，在用户无法登录数据库主机的场景下无法使用；

​	由于是通过拷贝物理文件实现的，源表和目标表都是使用 InnoDB 引擎时才能使用。

2、用 mysqldump 生成包含 INSERT 语句文件的方法，可以在 where 参数增加过滤条件，来实现只导出部分数据。这个方式的不足之一是，不能使用 join 这种比较复杂的 where 条件写法。

3、用 select … into outfile 的方法是最灵活的，支持所有的 SQL 写法。但，这个方法的缺点之一就是，每次只能导出一张表的数据，而且表结构也需要另外的语句单独备份。

后两种方式都是逻辑备份方式，是可以跨引擎使用的。 

### 评论问题

 如果 sessionA 拿到 c=5 的记录锁是写锁，那为什么 sessionB 和 sessionC 还能加 c=5 的读锁呢？ 

 这是因为 next-key lock 是先加间隙锁，再加记录锁的。加间隙锁成功了，加记录锁就会被堵住。如果你对这个过程有疑问的话，可以再复习一下第 30 篇文章中的相关内容。 

# 42 | grant之后要跟着flush privileges吗？

 grant 语句是用来给用户赋权的。 

 因此，正常情况下，grant 命令之后，没有必要跟着执行 flush privileges 命令。 

###  flush privileges 使用场景 

 当数据表中的权限数据跟内存中的权限数据不一致的时候，flush privileges 语句可以用来重建内存数据，达到一致状态。 

 这种不一致往往是由不规范的操作导致的，比如直接用 DML 语句操作系统权限表。 

### 小结

 grant 语句会同时修改数据表和内存，判断权限的时候使用的是内存数据。因此，规范地使用 grant 和 revoke 语句，是不需要随后加上 flush privileges 语句的。

flush privileges 语句本身会用数据表的数据重建一份内存权限数据，所以在权限数据可能存在不一致的情况下再使用。而这种不一致往往是由于直接用 DML 语句操作系统权限表导致的，所以我们尽量不要使用这类语句。 

# 43 | 要不要使用分区表？

```
CREATE TABLE `t` (
  `ftime` datetime NOT NULL,
  `c` int(11) DEFAULT NULL,
  KEY (`ftime`)
) ENGINE=InnoDB DEFAULT CHARSET=latin1
PARTITION BY RANGE (YEAR(ftime))
(PARTITION p_2017 VALUES LESS THAN (2017) ENGINE = InnoDB,
 PARTITION p_2018 VALUES LESS THAN (2018) ENGINE = InnoDB,
 PARTITION p_2019 VALUES LESS THAN (2019) ENGINE = InnoDB,
PARTITION p_others VALUES LESS THAN MAXVALUE ENGINE = InnoDB);
insert into t values('2017-4-1',1),('2018-4-1',1);
```

<img src="F:/项目/Git-md/ZJW-Summary/assets/1687098325003.png" alt="1687098325003" style="zoom:67%;" />

 按照定义的分区规则，这两行记录分别落在 p_2018 和 p_2019 这两个分区上。 

 可以看到，这个表包含了一个.frm 文件和 4 个.ibd 文件，每个分区对应一个.ibd 文件。

对于引擎层来说，这是 4 个表；

对于 Server 层来说，这是 1 个表。 

###  分区表的引擎层行为 

<img src="F:/项目/Git-md/ZJW-Summary/assets/1687098395387.png" alt="1687098395387" style="zoom:67%;" />

 使用分区表的一个重要原因就是单表过大。 

加锁可以更细分，理论上锁 冲突会更小，只是 单个分区维度的锁。无论是myisam还是innodb

###  分区表和手工分表

 分区表和手工分表，一个是由 server 层来决定使用哪个分区，一个是由应用层代码来决定使用哪个分表。因此，从引擎层看，这两种方式也是没有差别的。 

 从 server 层看，我们就不得不提到分区表一个被广为诟病的问题：打开表的行为。 

###  分区策略 

 **每当第一次访问一个分区表的时候，MySQL 需要把所有的分区都访问一遍**。一个典型的报错情况是这样的：如果一个分区表的分区很多，比如超过了 1000 个，而 MySQL 启动的时候，open_files_limit 参数使用的是默认值 1024，那么就会在访问这个表的时候，由于需要打开所有的文件，导致打开表文件的个数超过了上限而报错。 



从 MySQL 8.0 版本开始，就不允许创建 MyISAM 分区表了，只允许创建已经实现了本地分区策略的引擎。目前来看，只有 InnoDB 和 NDB 这两个引擎支持了本地分区策略。 

###  分区表的 server 层行为 

<img src="F:/项目/Git-md/ZJW-Summary/assets/1687099463276.png" alt="1687099463276" style="zoom:67%;" />

 由于 session A 持有整个表 t 的 MDL 锁，就导致了 session B 的 alter 语句被堵住。 



1、 MySQL 在第一次打开分区表的时候，需要访问所有的分区；

2、在 server 层，认为这是同一张表，因此所有分区共用同一个 MDL 锁；

3、在引擎层，认为这是不同的表，因此 MDL 锁之后的执行过程，会根据分区表规则（看具体sql条件可能会用到的分区表），只访问必要的分区。 

###  分区表的应用场景 

 使用分区表的业务代码更简洁 

  分区表可以很方便的清理历史数据，通过 alter table t drop partition ... 这个语法删掉分区， 与使用 delete 语句删除数据相比，优势是速度快、对系统影响小。 

### 小结

 实际使用时，分区表跟用户分表比起来，有两个绕不开的问题：一个是第一次访问的时候需要访问所有分区，另一个是共用 MDL 锁。 

 如果要使用分区表，就不要创建太多的分区。 

# 44 | 答疑文章（三）：说一说这些好问题

###  如果用 left join 的话，左边的表一定是驱动表吗？

如果两个表的 join 包含多个条件的等值匹配，是都要写到 on 里面呢，还是只把一个条件写到 on 里面，其他条件写到 where 部分？ 



 这个例子说明（优化器会将left优化成有索引的来当被驱动表），即使我们在 SQL 语句中写成 left join，执行过程还是有可能不是从左到右连接的。也就是说，使用 left join 时，左边的表不一定是驱动表。 

 这样看来，如果需要 left join 的语义，就不能把被驱动表的字段放在 where 条件里面做等值判断或不等值判断，必须都写在 on 里面。

### 那如果是 join 语句呢？ 

```
select * from a join b on(a.f1=b.f1) and (a.f2=b.f2); /*Q3*/
select * from a join b on(a.f1=b.f1) where (a.f2=b.f2);/*Q4*/
```

 使用一次看 explain 和 show warnings 的方法，看看优化器是怎么做的。 

```
select * from a join b where (a.f1=b.f1) and (a.f2=b.f2);
```

在这种情况下，join 将判断条件是否全部放在 on 部分就没有区别了。 



###  distinct 和 group by 的性能 

```
表T中a字段无索引
select a from t group by a order by null;
select distinct a from t;
```

 没有了 count(*) 以后，也就是不再需要执行“计算总数”的逻辑时，第一条语句的逻辑就变成是：按照字段 a 做分组，相同的 a 的值只返回一行。而这就是 distinct 的语义，所以不需要执行聚合函数时，distinct 和 group by 这两条语句的语义和执行流程是相同的，因此执行性能也相同。 

1、 创建一个临时表，临时表有一个字段 a，并且在这个字段 a 上创建一个唯一索引； 

2、 遍历表 t，依次取数据插入临时表中： 

​	 如果发现唯一键冲突，就跳过； 

​	 否则插入成功； 

3、 遍历完成后，将临时表作为结果集返回给客户端。 

###  备库自增主键问题 

...



# 45 | 自增id用完怎么办？

### rowid

如果不自己设置自增主键，那么rowid到最大后会从0-N再次开始分配，此时就会对原有数据行进行覆盖修改。

row id 2的42次方，innodb给的是8字节，实际只有6字节的。

### 自增id

表定义的自增值达到上限后的逻辑是：再申请下一个 id 时，得到的值保持不变。 

因此，应该在 InnoDB 表中主动创建自增主键。因为，表自增 id 到达上限后，再插入数据时报主键冲突错误，是更能被接受的。 

### Xid

 redo log 和 binlog 相配合的时候，提到了它们有一个共同的字段叫作 Xid。它在 MySQL 中是用来对应事务的。 

 全局变量 global_query_id ， 每次执行语句的时候将它赋值给 Query_id，然后给这个变量加 1。  如果当前语句是这个事务执行的第一条语句，那么 MySQL 还会同时把 Query_id 赋值给这个事务的 Xid。 

 

global_query_id 是一个纯内存变量，重启之后就清零了。所以你就知道了，在同一个数据库实例中，不同事务的 Xid 也是有可能相同的。 

 但是 MySQL 重启之后会重新生成新的 binlog 文件，这就保证了，同一个 binlog 文件里，Xid 一定是惟一的。 



 从理论上讲，还是就会出现同一个 binlog 里面出现相同 Xid 的场景。 因为这个8字节2的64次方的 全局id是循环着来的。

###  Innodb trx_id 

 Xid 是由 server 层维护的。InnoDB 内部使用 Xid，就是为了能够在 InnoDB 事务和 server 之间做关联。但是，InnoDB 自己的 trx_id，是另外维护的。 



 InnoDB 内部维护了一个 max_trx_id 全局变量，每次需要申请一个新的 trx_id 时，就获得 max_trx_id 的当前值，然后并将 max_trx_id 加 1。 



 InnoDB 数据可见性的核心思想是：每一行数据都记录了更新它的 trx_id，当一个事务读到一行数据的时候，判断这个数据是否可见的方法，就是通过事务的一致性视图与这行数据的 trx_id 做对比。 

###  thread_id 

 你不会在 show processlist 里看到两个相同的 thread_id。 因为有实时的唯一数组判断，这个id 不会重复。

###  小结 

1、 表的自增 id 达到上限后，再申请时它的值就不会改变，进而导致继续插入数据时报主键冲突的错误。

2、row_id 达到上限后，则会归 0 再重新递增，如果出现相同的 row_id，后写的数据会覆盖之前的数据。

3、Xid 只需要不在同一个 binlog 文件中出现重复值即可。虽然理论上会出现重复值，但是概率极小，可以忽略不计。 

4、thread_id 是我们使用中最常见的，而且也是处理得最好的一个自增 id 逻辑了。 