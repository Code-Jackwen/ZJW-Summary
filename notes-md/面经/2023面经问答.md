## 操作系统

#### 协程了解吗，它比线程好在哪

协程是一种轻量级的并发编程模型，与传统的线程相比，它具有一些优势。

**1. 轻量级：** **协程比线程更轻量级，因为它们不需要操作系统级别的线程和进程管理。一个进程中可以创建数千个甚至更多的协程而不会过多消耗系统资源。**

**2. 低开销：** 协程的**创建和销毁**开销比线程小得多。线程的创建和销毁通常涉及到操作系统级别的系统调用，而协程的创建和销毁只涉及用户级别的代码。

**3. 内存效率：** 每个线程都有自己的堆栈空间，而协程可以**在同一个线程中共享堆栈**。这意味着协程消耗的内存通常比线程少。

**4. 编程模型：** 协程通常使用同步的编程模型，使得编写异步代码更加直观和易于理解。它们可以避免回调地狱（callback hell）和复杂的多线程同步问题。

**5. 并发控制：** 协程可以通过**挂起和恢复**操作来控制并发。这种方式下，开发者可以更容易地实现复杂的并发逻辑，而**无需担心线程间的竞态条件和锁**。

**6. 高并发性：** 协程可以在单线程中实现高并发。多个协程可以在同一个线程内交替执行，而无需创建多个线程。

**7. 适用性：** 协程适用于某些特定的并发问题，例如网络通信、异步IO等。对于CPU密集型任务，线程可能更适合。

**8. 可移植性：** 协程通常更具可移植性，因为它们不涉及底层操作系统的细节。



补充缺点：

**依赖于调度策略：** 协程的调度完全由程序员控制，这意味着如果调度不当，可能会导致某些协程长时间占用CPU资源，而其他协程无法获得执行的机会。线程由操作系统进行调度，更容易实现公平的任务分配。

**不适合底层操作：** 在某些底层操作系统级别的任务中，例如设备驱动程序或操作系统内核，线程可能更合适，因为它们可以更容易地与底层操作系统交互。



#### 共享内存的实现

共享内存的创建和管理是在内核态完成的，而进程在用户态通过系统调用将共享内存映射到自己的地址空间中。

这样，多个进程可以在自己的地址空间中共享同一块内存区域，实现了高效的进程间数据交换。

需要注意的是，为了保证数据的一致性和避免竞态条件，通常需要在用户态使用额外的同步机制。



#### 进程间并发同步的方式？

问题奇怪。。



- 信号量是一种用于控制多个进程对共享资源访问的同步机制。它允许多个进程在临界区内执行，但通过设置信号量的值来控制并发访问的数量。
- 我猜的 fifo也算吧



#### 什么是用户态，什么是内核态

用户态

用户态下的程序通常不能执行特权指令，如修改页表、控制中断处理、更改CPU寄存器等。

大多数应用程序和用户级别的进程都在用户态下运行，因为这样可以提高系统的稳定性和安全性。



内核态

内核态下的程序可以执行特权指令，修改页表、处理中断、更改硬件状态等。



当应用程序需要执行特权操作（例如，请求文件读取或网络通信）时，它会发起系统调用，这将触发从用户态到内核态的切换，操作系统内核会处理请求，然后再返回用户态，使得应用程序可以继续执行。

总之，用户态和内核态是操作系统中的两种不同特权级别，用于控制程序和操作系统内核的执行权限，以确保系统的稳定性和安全性。



## linux

#### linux有tomcat访问日志，如何查今天访问量最大的？

`awk`和`sort`等命令，结合 grep。  答不好。。。

```
cat access.log | grep "$(date '+%Y-%m-%d')" | awk '{print $4}' | sort | uniq -c | sort -nr | head -n 10
```

1. `cat access.log`：用于将日志文件内容输出到标准输出。
2. `grep "$(date '+%Y-%m-%d')"`：这个部分用于筛选出包含今天日期的日志条目。`$(date '+%Y-%m-%d')`会获取当前日期，并将其作为搜索条件传递给`grep`命令。
3. `awk '{print $4}'`：使用`awk`命令提取每行中的第四个字段，通常是访问时间。
4. `sort`：将提取的访问时间进行排序。
5. `uniq -c`：对排序后的时间进行去重并计数每个时间出现的次数。
6. `sort -nr`：按访问次数倒序排序，以便最多访问的时间在顶部。
7. `head -n 10`：显示前10个访问次数最多的时间。

这个命令会输出今天访问量最大的前10个时间段。你可以根据需要调整数字来获取更多或更少的时间段。确保将"access.log"替换为你实际的Tomcat访问日志文件名。



#### linux大文件中查找指定字符串--dd+grep

https://blog.csdn.net/u011489186/article/details/105790272

```html
dd if=model_20200423155728 bs=1024 skip=3600000 count=1200 | grep '4222019284714124'
```

使用二分法找到了“4222019284714124”！关于 dd+grep 的用法，总结了几点：

每次从文件开头先跳过 skip*bs 大小的内容，复制 count*bs 大小的内容过来用 grep 查询。

如果不设置 count，就会查找跳过后剩余的整个文件，如果查到，则会有输出；否则无。

对于特别大的文件，可以不设置skip先把 count 设为一半文件大小的值，采用二分法查找。如果找到，则限定在了前半范围，否则在后半部分。使用类似的方法继续查找……

如果找到，最后会输出 count*bs 大小的内容



#### vmstat内存查看

`vmstat` 是一个用于查看Linux系统虚拟内存统计信息的命令。

**swap**

- `si`：每秒从磁盘交换到内存的数据量，以KB为单位。
- `so`：每秒从内存交换到磁盘的数据量，以KB为单位。

**system**

- `in`：每秒的中断数，包括时钟中断。
- `cs`：每秒的上下文切换数。



**Swap (swpd)**：

- **含义**：`swpd` 表示已经使用的交换空间的大小，以KB为单位。交换空间是硬盘上的一部分，用于将不常访问的内存数据移到磁盘上，以腾出物理内存供其他用途。
- **作用**：当物理内存不足时，操作系统会将不常用的内存页面交换到交换空间，以避免内存耗尽。如果 `swpd` 值持续增长，表示系统可能正在频繁地进行内存交换，这可能会导致性能下降。

Buffer (buff)**：

- **含义**：`buff` 表示用于磁盘缓冲的内存大小，以KB为单位。这些缓冲用于存储磁盘数据的副本，以加快对磁盘的读取操作。
- **作用**：磁盘缓冲帮助减少对磁盘的频繁访问，从而提高了系统的I/O性能。这些缓冲通常用于临时存储文件数据或块设备数据。

Cache (cache)**：

- **含义**：`cache` 表示用于文件缓存的内存大小，以KB为单位。文件缓存用于存储最近使用的文件数据的副本，以加快对文件的读取操作。
- **作用**：文件缓存提供了更快的文件读取速度，因为不必每次都从磁盘读取文件内容。这可以提高文件系统性能，尤其是在读取频繁访问的文件时。

总结：

- **`swpd` 表示已用交换空间，与内存不足时的内存交换有关。**
- **`buff` 表示磁盘缓冲，用于加速块设备数据的访问。**
- **`cache` 表示文件缓存，用于加速文件系统中文件的读取。**

在监视系统性能时，特别关注 `swpd` 字段，因为持续的内存交换可能会导致性能下降。同时，`buff` 和 `cache` 字段可以用来评估系统的I/O性能。



#### 为什么操作系统所有进程都要设计父进程？0号进程和1号进程

操作系统中设计父进程（通常是0号进程）和1号进程的原因是为了**管理和启动其他进程**，并确保操作系统的正常运行。这两个进程在Linux系统中通常被称为**init进程和systemd进程**。

这两个进程的存在确保了操作系统的稳定性和可管理性。它们提供了一个统一的入口点，使系统能够在启动时进行初始化，并且可以管理和控制其他用户进程的生命周期。此外，它们还提供了处理系统级事件和任务的机制，如关机、重启、日志记录等。

Init进程 是 1号 进程



**Systemd进程 (1号进程)**：gpt 未必对。。

- **现代初始化系统**：在现代Linux发行版中，1号进程通常是systemd，它是一种更先进的初始化系统，取代了传统的init系统。
- **并行启动**：systemd能够并行启动各种系统服务和进程，以提高系统的启动速度和效率。
- **资源管理**：它还负责资源管理、**进程监控、系统事件处理以及其他系统级任务**。



## TCP UDP

#### 为什么TCP的第三次握手可以携带数据？

原文链接：https://blog.csdn.net/qq_49641239/article/details/118527785

第三次握手的时候，是可以携带数据的。但是，第一次、第二次握手 不可以携带数据。



这是因为：第一次握手不可以放数据，其中一个简单的原因就是会让服务器更加容易受到攻击了。

比如：只需要在第一次握手中的 SYN 报文中放大量数据，那么服务器势必会消耗更多的时间和内存空间去处理这些数据，增大了服务器被攻击的风险。



而对于第三次的话，此时客户端已经处于 ESTABLISHED 状态。

对于客户端来说，他已经建立起连接了，并且也已经知道服务器的接收、发送能力是正常的了，所以能携带数据也没啥毛病。



#### 什么是SYN 攻击？如何避免 SYN 攻击？

来自 gpt3

SYN攻击（SYN Flood Attack）是一种网络攻击，目的是耗尽目标服务器的网络资源，通常是针对TCP协议的。

SYN攻击的攻击者通过发送大量伪造的TCP连接请求（SYN包），但不完成握手过程，从而导致目标服务器不断分配资源来处理这些伪造的连接请求，最终耗尽服务器的资源，使得合法的连接无法建立或服务受到严重影响。



**TCP SYN Cookie**：一种抵御SYN攻击的方法是启用TCP SYN Cookie。当服务器受到大量SYN请求时，它可以生成一个cookie作为响应，而不是分配资源并等待ACK。只有在客户端回应时，服务器才分配资源。这样可以防止攻击者耗尽服务器资源。



**使用CDN**：使用内容分发网络（CDN）可以分散流量，使攻击者难以集中攻击一个服务器。

**限制并发连接数**：在应用层或负载均衡器中，可以限制来自单个IP地址的并发连接数，从而减缓攻击速度。



#### TCP的粘包、拆包以及解决方案

https://cloud.tencent.com/developer/article/1804413



## 线程

#### 线程池如何关闭

**线程池如何关闭？关闭阻塞主进程吗？**

通常建议使用`shutdown()`方法来平稳地关闭线程池，会等待一段时间以确保所有线程都完成了任务再关闭

如果需要更快速地关闭线程池，可以使用`shutdownNow()`方法，但需要注意可能会有部分任务未完成。



#### 线程池 都有什么拒绝策略

**默认策略**：会抛出一个`RejectedExecutionException`异常，表示拒绝执行新任务。

**CallerRunsPolicy**：如果线程池无法接受新任务，它会将任务返回给提交任务的线程来执行。这个策略可能会导致调用线程被阻塞，因为它需要等待线程池中的一个线程空闲下来。

**DiscardPolicy**：默默地丢弃掉这个任务，不会抛出异常，也不会执行该任务。

**DiscardOldestPolicy**：它会丢弃掉队列中最早加入的任务（即队列头部的任务），然后尝试重新将新任务加入队列。



#### 线程池调度策略

https://juejin.cn/s/java%E7%BA%BF%E7%A8%8B%E6%B1%A0%E8%B0%83%E5%BA%A6%E7%AD%96%E7%95%A5

Java线程池使用的调度策略有以下几种：

1. FIFO(先进先出)：已经在队列中等待的任务按照它们加入队列的顺序来被执行。
2. LIFO(后进先出)：新加入队列的任务将会放到队列的最前面，会优先执行。
3. 优先级：任务会根据它们的优先级顺序被执行。
4. 定时任务：任务会在指定的时间被执行。

在Java中，线程池默认使用FIFO调度策略。如果要使用其他策略，可以使用PriorityBlockingQueue或DelayQueue等队列来实现。



threadFactory：线程工厂，用来创建线程，若不设置则使用默认的工厂来创建线程，这样新创建出来的线程会具有相同的优先级，并且是非守护的线程，同时也会设置好名称



#### 线程核心数和最大数配置

https://juejin.cn/post/7072281409053786120



#### synchronized 、 ReentrantLock 的区别

性能相当

灵活性：ReentrantLock ，绑定多个 condition，**锁绑定多个条件**， 更好

实现上：JVM、jdk

可重入：都支持，而 ReentrantLock 必须在每个 `lock()` 调用后对应一个 `unlock()` 调用，否则会导致死锁。

公平性：默认非公平，ReentrantLock 还可以公平

等待可中断：当持有锁的线程长期不释放锁的时候，正在等待的线程可以选择放弃等待，改为处理其他事情。

ReentrantLock 可中断，而 synchronized 不行。



#### 多调 unlock 会怎样？

IllegalMonitorStateException：

1、在没有获得对象的监视器锁的情况下尝试调用 `wait()`、`notify()` 或 `notifyAll()` 方法

2、**在不拥有对象的监视器锁的情况下尝试调用 `synchronized` 块或方法**

3、或者就是 多调用了 unlock 。



#### AQS 

https://blog.csdn.net/u012988901/article/details/112251913



#### synchronized底层原理

`synchronized` 是 Java 中用于实现线程同步的关键字，它的底层原理与**监视器（Monitor）机制**密切相关。

**底层原理**：

1. **Monitor（监视器）**：每个Java对象都与一个Monitor关联。Monitor是一种同步机制，用于确保只有一个线程可以同时访问一个对象的临界区（同步块或同步方法）。
2. **Enter Monitor（进入监视器）**：当一个线程试图进入一个由`synchronized`修饰的临界区时，它会尝试获取该对象的Monitor。如果Monitor没有被其他线程占用，线程将成功进入临界区，执行相应的代码。
3. **Exit Monitor（退出监视器）**：当线程离开临界区时，它会释放该对象的Monitor，以便其他线程可以进入。
4. **互斥性**：Monitor确保了临界区的互斥性，即同一时刻只有一个线程可以进入临界区。
5. **等待队列**：如果线程尝试进入一个被其他线程占用的Monitor，它将被阻塞，放入Monitor的等待队列，等待其他线程释放Monitor。

所以，`synchronized` 的底层原理与Monitor密切相关，它通过Monitor来实现线程之间的同步和互斥，确保多个线程安全地访问临界区。

需要注意的是，虽然`Lock`接口及其实现类也提供了替代`synchronized`的同步机制，但它们的底层实现仍然依赖于Monitor，因为Monitor是Java中实现线程同步的基础。不过，`Lock`提供了更灵活的方式来管理锁的获取和释放，可以更精细地控制锁的行为。





## 分布式锁

需要注意的问题：

释放超时：异常 捕捉后再次 释放

最长超时时间：避免 出问题不释放锁，影响锁下一次 获取

可重入：TL + 变量实现

锁的续租：额外一个 守护线程可以实现， 定时续租，用于处理  阻塞类 长业务，且可以保证锁的可靠性

SetNX：用于实现 ，键不存在时设置键的值。

稳定性：过半数获取到 锁才算 获取到，半数成功才成功。



续租：

**原理：**

1. 每个应用程序实例尝试获取锁时，使用`SETNX`命令设置一个特定的键，如果成功获得锁，该键的值会被设置为唯一的标识符（例如实例的ID）。
2. 应用程序实例在获取锁后，启动一个定时任务，定期（比锁的过期时间略短的时间间隔）执行续租操作。
3. 续租操作使用`EXPIRE`命令来延长锁的过期时间，确保锁不会在获取后立即过期。
4. 如果应用程序实例在续租期间宕机或执行出错，由于Redis的锁是有过期时间的，锁最终会在过期后被自动释放，其他实例可以尝试获取锁。

```java
import redis.clients.jedis.Jedis;
import java.util.UUID;

public class RedisDistributedLockDemo {

    private static final String LOCK_KEY = "myLock";
    private static final int LOCK_EXPIRE_TIME = 30; // 锁的过期时间，单位：秒
    private static final int RENEW_INTERVAL = 10;   // 续租间隔时间，单位：秒

    public static void main(String[] args) {
        Jedis jedis = new Jedis("localhost", 6379);

        // 生成一个唯一的标识符，用于标识当前实例
        String instanceId = UUID.randomUUID().toString();

        // 尝试获取锁
        boolean locked = acquireLock(jedis, instanceId);
        if (locked) {
            System.out.println("成功获取锁");

            // 启动续租线程
            startRenewalThread(jedis, instanceId);

            // 模拟业务逻辑
            try {
                Thread.sleep(20000); // 模拟业务处理时间
            } catch (InterruptedException e) {
                e.printStackTrace();
            }

            // 释放锁
            releaseLock(jedis, instanceId);
        } else {
            System.out.println("获取锁失败");
        }

        // 关闭Redis连接
        jedis.close();
    }

    private static boolean acquireLock(Jedis jedis, String instanceId) {
        Long result = jedis.setnx(LOCK_KEY, instanceId);
        if (result == 1) {
            // 成功获取锁，设置锁的过期时间
            jedis.expire(LOCK_KEY, LOCK_EXPIRE_TIME);
            return true;
        }
        return false;
    }

    private static void startRenewalThread(final Jedis jedis, final String instanceId) {
        Thread renewalThread = new Thread(() -> {
            while (true) {
                try {
                    // 休眠一段时间后续租锁
                    Thread.sleep(RENEW_INTERVAL * 1000);
                    jedis.expire(LOCK_KEY, LOCK_EXPIRE_TIME);
                    System.out.println("锁已续租");
                } catch (InterruptedException e) {
                    e.printStackTrace();
                }
            }
        });
        renewalThread.setDaemon(true);
        renewalThread.start();
    }

    private static void releaseLock(Jedis jedis, String instanceId) {
        // 首先检查当前持有锁的实例是否是当前实例，避免误释放锁
        String currentValue = jedis.get(LOCK_KEY);
        if (currentValue != null && currentValue.equals(instanceId)) {
            jedis.del(LOCK_KEY);
            System.out.println("成功释放锁");
        }
    }
}
```

这个示例中，每个应用程序实例尝试获取锁后，会启动一个续租线程，定期执行续租操作，确保锁不会过期。如果实例宕机或出错，锁会在过期后自动释放。这种方式保证了锁的可靠性和安全性，同时能够应对实例的故障情况。



### Redisson 原理

Redisson是一个基于Redis的分布式Java对象框架，它提供了分布式锁的功能，包括定时续租锁。它的原理涉及以下关键概念和技术：

1. **RedLock算法：** Redisson使用RedLock算法来实现分布式锁。RedLock是一个多Redis节点的分布式锁算法，它通过在多个Redis节点上获取锁，以提高可靠性和鲁棒性。要获取锁，客户端需要在多个Redis节点上获取锁，只有在多数节点成功获取锁时，锁才会被认为是获取成功。这样可以防止单个节点的宕机或网络问题导致的锁丢失问题。
2. **WatchDog机制：** Redisson使用WatchDog机制来实现锁的续租。当一个客户端成功获取锁时，它会在Redis中设置一个带有超时时间的锁键。同时，客户端会启动一个WatchDog线程，定期去续租这个锁。续租的过程就是不断地更新锁键的超时时间。如果客户端在规定的时间内没有续租成功，那么其他客户端有机会获取这个锁。
3. **异步操作：** Redisson使用异步操作来执行续租操作，这样可以防止阻塞主业务线程。当续租操作失败或超时时，Redisson会尝试重新获取锁，以确保锁的有效性。
4. **监听器机制：** Redisson提供了锁的监听器机制，允许客户端注册锁的监听器，以便在锁的状态发生变化时得到通知。这可以用于处理锁的释放、续租等事件。

总的来说，Redisson通过使用RedLock算法来确保锁的可靠性，通过WatchDog机制来实现锁的定时续租，通过异步操作和监听器机制来提供灵活性和可观测性。这些机制共同确保了Redisson分布式锁的高可用性和可靠性，适用于各种分布式应用场景。



###  lua 脚本 与原子性

redis + lua 脚本 可以实现 批量加锁的 原子性吗？ 比如 a、b、c三个锁 同时加成功或者 同时加 失败



## IO



**Netty相关**



**Netty NIO原理**

GPT 实际说的 Java NIO

Java NIO（New I/O）是Java提供的一种I/O处理方式，用于处理非阻塞式I/O操作。

通道（Channel）：用于读取和写入数据，类似 in 、out 那些类

缓冲区（Buffer）：和通道绑定，类似Buffer 那些修饰器类

选择器（Selector）：单个线程同时管理多个通道，实现了非阻塞式I/O。选择器会监视多个通道的状态，并告诉

程序哪些通道已经准备好读或写。



**Netty有哪些组件**

Channel：一个可以进行I/O操作的通道

`EventLoop`负责处理`Channel`上的事件，包括I/O事件、定时任务等

ChannelPipeline（通道管道）：数据在进出`Channel`时会经过`ChannelPipeline`中的一系列处理器，每个处理器负责执行特定的任务，如编码、解码、数据处理等。

编解码器（Codec）：处理数据的序列化和反序列化，以及不同的数据格式。



**Netty 用的堆内内存还是堆外内存 怎么管理?**

Netty在内部使用堆外内存（Off-Heap Memory）来管理网络数据，这是为了提高性能和减少垃圾回收的影响。

直接分配在操作系统的本机内存中，而不受Java堆内存管理的影响。



涉及两个组件：

**ByteBuf（字节缓冲区）**

**内存池（Memory Pool）**

Netty的内存池通常包括两个部分：堆外内存池和直接内存池。堆外内存池用于存储数据，直接内存池用于存储`ByteBuf`对象的元数据。



## JVM



#### Yong GC怎么进行的?

扫描范围：Eden 和 From 区

**垃圾收集**：在Minor GC过程中，垃圾收集器会扫描Eden区和From区，识别出不再被引用的对象，将它们标记为垃圾。存活的对象会被复制到To区。同时，Survivor区中的对象也会根据它们的年龄，部分晋升到老年代。

**年龄增加**：在每次Minor GC后，存活的对象的年龄会增加。当它们的年龄达到一定阈值时，它们会晋升到老年代。



#### JVM跨代引用如何解决？

陌生。

跨代引用是指一个对象引用另一个代（如年轻代引用老年代对象）的情况。这种情况可能会导致一些复杂性，因为不同代的垃圾收集策略不同。解决跨代引用的主要方法是确保对象在垃圾回收时能够正确被追踪和处理，以避免内存泄漏和一致性问题。

1、一种常见的方法是使用弱引用（Weak Reference）或软引用（Soft Reference）来跟踪跨代引用的对象。

2、**手动管理引用**：确保在不再需要引用的情况下将其释放。这可以通过设置引用为`null`来实现

3、**避免跨代引用**：可能需要重新考虑对象的生命周期和引用关系，以降低跨代引用的发生频率。



#### Metaspace 是 gc 的清理区域吗？

在Java 8及更高版本中，Metaspace（元空间）并**不是**垃圾收集（GC）的清理区域。相反，Metaspace是用于存储类的元数据信息（如类的结构、方法、字段等）的区域，它不参与常规的Java堆内存的垃圾收集过程。

我：但是 空间不够 会出现  oom。

满了会  Full GC！



#### 方法区中的内存能被回收吗？

被回收需要满足什么条件？

从Java 8开始，方法区中的一部分被逐渐纳入到了Java堆中的"永久代（Permanent Generation）"或"元空间（Metaspace）在这种情况下，方法区中的一部分内存是可以被垃圾回收的。

要使方法区中的内存被回收，通常需要满足以下条件：

1. 类不再被引用：当一个类不再被任何活动的类加载器引用，并且没有任何其他引用时，该类的元信息和相关数据可以被回收。
2. 永久代或元空间溢出：如果永久代或元空间的内存不足，JVM可能会触发垃圾回收来释放不再使用的类的元信息和相关数据，以腾出内存空间。
3. 类加载器的生命周期结束：如果一个类加载器的生命周期结束（例如，Web应用程序被卸载），那么由该类加载器加载的类的元信息和数据也会被回收。

需要注意的是，从Java 8开始，永久代被废弃，取而代之的是元空间。元空间的内存由操作系统管理，因此不再存在永久代内存溢出的情况。**但是，元空间仍然需要垃圾回收来释放不再使用的类的内存。**

总之，方法区中的内存通常不会被频繁回收，但在一些特定情况下，可能会触发垃圾回收来释放不再使用的类的元信息和相关数据。



#### 对象只能在堆上分配吗？

如果在栈上分配，除了逃逸分析外，还要有什么条件？

局部变量：对象必须是方法的局部变量，不能是实例变量或静态变量。因为局部变量的生命周期受限于方法的执行时间，当方法结束时，局部变量也会随之销毁。

**对象不逃逸**：对象不能逃逸到方法之外，也就是说，对象不能被方法返回或传递给其他方法，否则会导致对象的引用超出了方法的作用域，从而不能在栈上分配。

**编译器支持**：编译器需要支持栈上分配的优化。通常，这需要进行逃逸分析，以确定对象是否逃逸。如果编译器能够确定对象不会逃逸，它可以选择在栈上分配对象内存。



#### G1收集器一定不会产生内存碎片吗？

在极端情况下，仍然可能发生内存碎片。例如，如果应用程序生成**大量长生命周期的对象**，这些对象可能会在**老年代中产生内存碎片**。此外，G1的收集行为也受到许多因素的影响，包括堆的大小、应用程序的行为、G1的配置等。



#### G1收集器的大对象如何分配？

G1收集器会将该对象直接分配到老年代（Tenured Generation）中，而不是分配到年轻代。

**Humongous区域**：为了更好地管理大对象，G1收集器引入了Humongous区域。当一个大对象被分配时，G1会检查它的大小，如果大于或等于一个Humongous区域的一半，那么它将被直接分配到一个Humongous区域中。Humongous区域可以被独立地回收，以减少大对象的碎片问题。



#### G1大对象如何回收？G1收集器会发生Full GC吗？

尽管G1收集器努力减少Full GC的发生，但在一些情况下仍然可能发生Full GC。

- 当老年代的垃圾回收周期无法释放足够的内存空间来满足应用程序的需求时。
- 当Humongous区域无法找到足够的连续内存来分配大对象时。



#### **为什么要有Survivor区**

Survivor的存在意义，就是减少被送到老年代的对象，进而减少Full GC的发生，Survivor的预筛选保证，只有经历16次Minor GC还能在新生代中存活的对象，才会被送到老年代。

#### **为什么要设置两个Survivor区**

解决碎片化空间、空间不连续问题、以及GC时长问题（如果单个 sur区 还必须 要空间连续的话，后续多次清理时间受阻碍）

整个过程中，永远有一个survivor space是空的，另一个非空的survivor space无碎片。





拓展：Survivor为什么不分更多块呢？

比方说分成三个、四个、五个?显然，如果Survivor区再细分下去，每一块的空间就会比较小，很容易导致Survivor区满，因此，我认为两块Survivor区是经过权衡之后的最佳方案。



#### cinit方法

用于执行类的静态变量初始化和静态代码块

`<clinit>`方法只会在类加载的过程中执行一次，确保类的静态成员变量在类加载时被正确初始化。

如果执行失败了，不能再使用。

类一旦初始化失败，将无法使用，因为其静态变量没有被正确初始化



#### 如何打破双亲委派模型？

双亲委派模型：
是Java类加载机制的一部分，用于确保类的安全性和一致性。这个模型有助于防止不同类加载器加载同一个类，从而避免类的冲突和安全漏洞。

以下是创建自定义类加载器的一般步骤：

1. 创建一个继承自`ClassLoader`的子类。
2. 覆盖`findClass`方法，实现自定义的类加载逻辑。在该方法中，你可以指定从哪里加载类字节码，然后调用`defineClass`方法来定义类。
3. 可以选择覆盖`loadClass`方法来改变类加载器的加载行为，但要小心不要破坏双亲委派模型的一致性。



#### 双亲委派模型的作用？

1. 避免类的重复加载：当Java程序启动时，会创建一个叫做"根类加载器（Bootstrap ClassLoader）"的类加载器，它负责加载Java标准库中的类，如`java.lang.String`等。根类加载器没有父加载器，是所有类加载器的顶级加载器。当一个类需要被加载时，首先会询问其父加载器是否已经加载了该类，如果父加载器已加载，则直接使用父加载器加载的类，避免了重复加载，节省了内存。这种层级化的类加载机制形成了双亲委派模型。
2. 安全性：双亲委派模型可以增强Java程序的安全性。由于父加载器优先加载类，恶意代码无法轻易替换标准库中的类，因为它们的类加载器不是根类加载器。这可以有效防止恶意类的加载和执行。

总结一下，双亲委派模型的作用是确保类加载的层级结构和防止恶意代码的加载，从而提高了Java程序的安全性和性能。



#### 可以加载java.lang包下的类？

**可以通过自定义类加载器加载java.lang包下的类吗？**

应该是可以。。。



**方法区中的内存能被回收吗？被回收需要满足什么条件？**

从Java 8开始，方法区中的一部分被逐渐纳入到了Java堆中的"永久代（Permanent Generation）"或"元空间（Metaspace）"中，具体的实现取决于JVM的版本和配置。在这种情况下，方法区中的一部分内存是可以被垃圾回收的。





#### 线程的类加载器

很陌生。

例如在J2EE容器中，不同的Web应用程序可能使用不同的类加载器，以隔离彼此的类。

线程的类加载器允许不同线程加载不同的类，从而实现类加载的隔离和灵活性。



Java中线程的类加载器通常有两种：

**上下文类加载器（Context Class Loader）**：线程可以通过获取上下文类加载器来加载类。这个类加载器可以通过 `Thread` 类的 `getContextClassLoader()` 方法获取。上下文类加载器是Java中线程上下文相关的类加载器，通常用于解决一些特定的类加载问题，例如在J2EE容器中的类加载，或者在不同模块之间的类加载。它允许线程加载与其自身类加载器不同的类。

**系统类加载器（System Class Loader）**：除了上下文类加载器，每个线程还有一个默认的类加载器，它是系统类加载器，也被称为应用类加载器。系统类加载器负责加载应用程序中的类，通常是从类路径（Classpath）中加载类文件。





#### 类加载器

在Java中，数组是由Java虚拟机（JVM）自动创建的对象，而不是由类加载器加载的类。因此，数组本身没有与类加载器相关的概念。





## Mysql

#### 连接查询优化

参考：https://mp.weixin.qq.com/s/Ykxvv87XqIeW9AsYUDqMXQ

连接查询优化，小表驱动大表，大表（被驱动表）建立索引，小表会被放在内存里，扫描小表次数的大表



#### 主键、唯一键的区别

https://blog.51cto.com/u_14479502/3116862

一、主键索引和唯一索引的区别
（1）主键是一种约束，唯一索引是一种索引，两者在本质上是不同的。

**（2）主键创建后一定包含一个唯一性索引，唯一性索引并不一定就是主键。**

**（3）唯一性索引列允许空值，而主键列不允许为空值。**

**（4）主键可以被其他表引用为外键，而唯一索引不能。**

**（5）一个表最多只能创建一个主键，但可以创建多个唯一索引。**

（6）主键更适合那些不容易更改的唯一标识，如自动递增列、身份证号等。



其他约束：主键约束、非空约束、非空约束、唯一约束....。



#### 外键

外键：首先他是表中的一个字段，虽可以不是本表的主键，但要对应另外一个表的主键。外键的主要作用是保证数据引用的完整性，**定义外键后，不允许删除在另一个表中具有关联关系的行。外键的作用是保持数据的一致性、完整性。**

删除的话应该是 删除 外键表数据，然后再删除 主表数据， 外键是从表，主键是主表。



http://c.biancheng.net/view/2441.html

主表删除某条记录时，从表中与之对应的记录也必须有相应的改变。一个表可以有一个或多个外键，外键可以为空值，若不为空值，则每一个外键的值必须等于主表中主键的某个值。

外键约束会降低数据库的性能，大部分互联网应用程序为了追求速度，并不设置外键约束，而是仅靠应用程序自身来保证逻辑的正确性。

廖雪峰：https://www.liaoxuefeng.com/wiki/1177760294764384/1218728424164736



#### 分库分表

俩文章一般吧~

https://zhuanlan.zhihu.com/p/342814592

https://cloud.tencent.com/developer/news/243312

1. 分区：把一张表的数据分成多个区块，在逻辑上看最终只是一张表，但底层是由多个物理区块组成的
2. 分表：把一张表按一定的规则分解成多个具有独立存储空间的实体表。系统读写时需要根据定义好的规则得到对应的字表明，然后操作它。
3. 分库：把一个库拆成多个库，突破库级别的数据库操作I/O瓶颈。另外，一台[服务器](https://cloud.tencent.com/act/pro/promotion-cvm?from=20067&from_column=20067)的资源（CPU、磁盘、内存、IO等）是有限的，最终数据库所能承载的数据量、数据处理能力都将遭遇瓶颈,。

**分库分表存在的问题**

 事务问题。

跨库跨表的join问题。

额外的数据管理负担和数据运算压力。



#### join、left join

会去除 null ，如果 a b 一条相等的都映射不上，那结果是 0 。

left join 的话 最少是 a 的条数，最多是 a*b * a





## Redis

#### Redis 三种模式分析

架构师、Redis 各种模式分析、有优缺点

https://mp.weixin.qq.com/s/pZ1P34Y1bHJTP49id718QQ

补充：小文章（不算太好，说的也对）分析优缺点：https://segmentfault.com/a/1190000043544891#item-2-4

集群模式

优点：

集群完全去中心化，采用多主多从；所有的redis节点彼此互联(PING-PONG机制)，内部使用二进制协议优化传输速度和带宽。

客户端与 Redis 节点直连，不需要中间代理层。客户端不需要连接集群所有节点，连接集群中任何一个可用节点即可。

每一个master节点负责维护一部分槽，以及槽所映射的键值数据；集群中每个节点都有全量的槽信息，通过槽每个node都知道具体数据存储到哪个node上。

容易横向扩展。



缺点：

数据分散，批处理 麻烦 mget。

当redis节点很多的时候，由于每个节点都需要跟其他节点通信，整个集群的性能会降低。

维护成本较高



芋道源码 

https://mp.weixin.qq.com/s/knyP1Jxo3C0s_s_xMVUv1w

集群详解：

https://blog.csdn.net/a745233700/article/details/112691126

09 | 切片集群：数据增多了，是该加内存还是加实例？

https://time.geekbang.org/column/article/276545



#### Redisson

最强分布式锁工具：Redisson

芋道源码，看的不是很懂，AQS说的可以，有公平锁原理

https://mp.weixin.qq.com/s/xvAwM0DCJAYx8V4KRQbJ8A

看了个图

https://mp.weixin.qq.com/s/AVN0FU5n1YYTTOtAdo6D2Q

石衫，很一般

https://mp.weixin.qq.com/s/y_Uw3P2Ll7wvk_j5Fdlusw



悟空，可以！青铜到 王者：

https://mp.weixin.qq.com/s/l9lcFqfXVI30qJi1r2A5-A

https://mp.weixin.qq.com/s/ZN2xhTrjH-GVNKapWGXTZA



## Java 基础

参考：CSDN ，收藏 Java基础

#### 字符串大小计算

100w个 32长度的uuid字符串 存到 String 数组里约 100M

1w个2长度的uuid字符串 存到 String 数组里约 1M


具体1个的大小是  40字节+ 2*len字节

40 包含 16字节的 对象头，类元指针引用， 和 char 数组等等



#### ConcurrentHashMap 不可以为什么不存null

可以：https://xie.infoq.cn/article/430746f01ca50357646db3e88

**在非并发的 Map 中（如 HashMap)，是可以容忍模糊性（二义性）的，而在并发 Map 中是无法容忍的。**

当你拿到 null 的时候，你是不知道他是因为本来就存了一个 null 进去还是说就是因为没找到而返回了 null。

在 HashMap 中，因为它的设计就是给单线程用的，所以当我们 map.get(key)返回 null 的时候，我们是可以通过 map.contains(key)检查来进行检测的，如果它返回 true，则认为是存了一个 null，否则就是因为没找到而返回了 null。

但是，像 ConcurrentHashMap，它是为并发而生的，它是要用在并发场景中的，当我们 map.get(key)返回 null 的时候，是没办法通过通过 map.contains(key)检查来准确的检测，因为在检测过程中可能会被其他线程锁修改，而导致检测结果并不可靠。

所以，为了让 ConcurrentHashMap 的语义更加准确，不存在二义性的问题，他就不支持 null。



#### Fail-Fast

Fail-Fast" 行为是 Java 集合框架的一种设计决策，用于检测并发修改，确保迭代器和集合的一致性。在编程时，要注意不要在迭代过程中修改集合，以避免 `ConcurrentModificationException` 异常。



**多线程并发修改**：如果多个线程同时访问并修改同一个 `ArrayList` 实例，并且至少一个线程是修改操作（如添加、删除）时，可能会导致 "Fail-Fast" 行为。

为了避免 "Fail-Fast" 行为，你可以采取以下措施之一：

- 在迭代过程中不要修改集合。如果需要修改，可以通过迭代器的方法来进行（如 `iterator.remove()`）。
- 在多线程环境下，使用线程安全的集合类，如 `CopyOnWriteArrayList`，以避免并发修改问题。



#### SynchronizedList和 vector的区别

讲 SynchronizedList和 vector的区别： https://blog.csdn.net/w372426096/article/details/80679665

我：1、SynchronizedList可以 自己输入锁 对象

2、实现上是代码块的锁，比vector 锁 小。vector 都是 方法级别的锁，锁 this

3、扩容机制不同也就是 arraylist和 vector的区别

4、Collections 装饰者模式 可以转换 LinkedList 为线程安全。



#### CopyOnWriteArrayList 与 Collections.synchronizedList();

`CopyOnWriteArrayList` 和 `Collections.synchronizedList` 都是用于多线程环境下的线程安全容器，但它们的原理和使用方式有所不同。

1. **CopyOnWriteArrayList**：
   - **原理**：`CopyOnWriteArrayList` 使用一种称为"写时复制"的策略。当对集合进行修改（添加、删除元素）时，它会先复制一份原始数据，并在新的副本上执行修改操作，然后将新副本替换原始数据。这意味着读操作可以并发进行，而写操作会创建一个新的副本，不会影响正在进行的读操作。因此，`CopyOnWriteArrayList` 适用于读多写少的场景，但写操作的代价较高。
   - **优点**：适用于读多写少的情况，提供了一种高度线程安全的读取机制，无需额外的同步。
   - **缺点**：由于写操作需要复制数据，写操作的性能较差，不适合频繁的写操作。
2. **Collections.synchronizedList**：
   - **原理**：`Collections.synchronizedList` 是通过包装（装饰器模式）将普通的 `List` 转换为线程安全的 `List`。它使用锁来同步对集合的读和写操作，确保只有一个线程能够访问集合的修改方法。
   - **优点**：提供了传统的线程安全，适用于多线程环境下的各种读写操作。
   - **缺点**：在高并发情况下，性能可能不如其他更高级的并发集合，因为它在整个集合上使用了单一的锁，可能导致性能瓶颈。

区别总结：

- `CopyOnWriteArrayList` 适用于读多写少的情况，写操作的性能较差，但读操作性能较好。它不需要额外的同步机制。
- `Collections.synchronizedList` 适用于一般的多线程读写场景，它使用锁来同步读和写操作，性能可能在高并发情况下受到影响。

选择哪种容器取决于你的应用场景和性能需求。如果需要高效的读取并且写操作不频繁，可以考虑使用 `CopyOnWriteArrayList`。如果需要更通用的线程安全性，可以使用 `Collections.synchronizedList`，但要注意它可能在高并发下性能较差。在某些情况下，也可以考虑使用其他并发集合类，如 `ConcurrentHashMap`。



#### ThreadLocal

弱引用： 如果弱引用 指向的对象只存在 这一条线路，则在喜爱一次ygc会被回收。ygc的时间不确定，进而弱引用被回收也不确定性。

WeakReference典型应用在 WeakHashMap。

例子：WeakHashMap 的的 key 设置为 null 后下次 这个map 的size  必 - 1.。。而HashMap的话不会。



ThreadLocal的 entry 是 弱引用。entry 的key 就是ThreadLocal对象。

设计用意：

当线程 执行完毕时，线程对象被内的实例属性会被垃圾回收。

而因为 弱引用的 存在，即使线程正在执行中，只要 ThreadLocal  被置为null，entry的 key 就会被喜爱一次 ygc回收。

而ThreadLocal  使用 set和get时 又会自动将 key == null 的置为 null，使value 能在下一次被回收。



但是，ThreadLocal 被建议为 static 引用，进而其生命周期 不会随着 线程的结束而结束。





get方法：获取 线程，进而获取ThreadLocalMap.Entry，进而获取 value ，而 没有 map的话，会执行set initailValue 方法 返回初始值。



一个 Thread 仅有 1个 ThreadLocalMap 对象。

1个 ThreadLocalMap 对象 可以存储多个 entry 对象。

1个 entry 对象的 key 弱引用 指向 一个  ThreadLocal 对象。



一个 ThreadLocal 对象，被多个 Thread 共享。

ThreadLocal 不持有 value，value由线程的 entry 对象持有。



作用：传递上下文，线程安全。



反作用：

脏读：

例子，一个线程池中1个 线程，上一个set 以后没有 remove ，下一个线程 没有set 而 直接get ，得到的之前线程的旧值。

内存泄露：在源码里，提示使用 static 修饰 ThreadLocal ，这样的话，ThreadLocal  对象失去引用后，触发弱引用机制来回收 entry 就不现实了。

上方示例 如果不 remove 那么 set 的对象 就会 不会被释放。



#### 内存泄漏

内存泄漏（Memory Leak）是指在程序运行过程中，分配的内存无法被释放，导致系统中的可用内存不断减少，最终可能耗尽可用内存资源。内存泄漏通常是由于程序未正确释放已分配的动态内存而引起的，这可能会导致程序性能下降或崩溃。



#### C++二维数组按行遍历和按列遍历的区别

https://blog.csdn.net/yizhiniu_xuyw/article/details/122449506

访问数组元素时，CPU不会每次只从内存中读取一个元素，而是读取一个区域的元素。假设二维数组的大小为（10 x 10），访问第一个元素时，CPU也会读取它的相邻元素

CPU缓存一次只能读取数组不到一行的数据，因此按列访问元素时每访问一个元素都要访问内存，因此速度就会慢很多。



## Spring

#### IoC 和 AOP

https://mp.weixin.qq.com/s/9_lUOU2tgVUf5VMZImfWJA





#### @autowire 和 @resource 的区别

GPT3

**匹配方式**：

- `@Autowired`默认按类型（byType）进行自动装配。它会尝试在容器中查找与要注入的字段或方法参数类型匹配的Bean，并注入它。
- `@Resource`默认按名称（byName）进行自动装配。它会尝试按照Bean的名称匹配要注入的字段或方法参数。

**名称匹配**：

- 在`@Autowired`中，如果有多个匹配的Bean，可以结合`@Qualifier`注解来指定具体的Bean名称。
- 在`@Resource`中，默认情况下，通过`name`属性指定要注入的Bean的名称。

**可选性**：

- `@Autowired`是非强制性的，如果找不到匹配的Bean，字段或方法参数可以为null。但你可以使用`@Autowired(required = true)`来要求强制装配。
- `@Resource`是强制性的，如果找不到匹配的Bean，会抛出异常。

**支持字段和方法注入（多种注入）**：

- `@Autowired`可以用于字段、构造函数、Setter方法等多种方式进行注入。
- `@Resource`通常用于字段和Setter方法的注入，不支持构造函数注入。



#### Spring MVC 父子容器

陌生。

在 Spring MVC 中，父子容器是一种容器层次结构，用于管理应用程序的不同组件。

总之，Spring MVC 中的父子容器模式有助于将应用程序分层、模块化和组织，并提供了一种良好的设计方式，使得应用程序更容易维护和扩展。根容器和 Web 应用程序上下文之间的关系允许你在全局和局部之间管理组件，提高了灵活性和性能。







## MyBatis

#### 有哪些注解

基础点的：

**@SelectKey**：用于在插入操作后获取生成的主键值。

1. **@Mapper**：将一个接口标记为 MyBatis 的映射器接口。MyBatis 会自动扫描这些接口并生成对应的实现类。
2. **@Select**：用于在映射器接口的方法上，指定一个 SQL 查询语句，以获取数据。
3. **@Insert**：用于在映射器接口的方法上，指定一个 SQL 插入语句，以插入数据。
4. **@Update**：用于在映射器接口的方法上，指定一个 SQL 更新语句，以更新数据。

拦截器相关点的：

开发者⾃⼰定义⼀个类，实现Interceptor接⼝，实现intercept⽅法，在类上通过@Intercepts注解和

@Signature选择拦截哪个类中的哪个⽅法，比如：

@Intercepts(@Signature(type =

ResultSetHandler.class, method = "handleResultSets", args = Statement.class))

然后那⾃定义

拦截器的类配置到mybatis的配置⽂件中。在加载mybatis的时候会去在执⾏到ResultSetHandler的时

候⽣成拦截器器的链，后⾯去调⽤会⾛拦截器





## 分布式



#### Raft和Paxos对比分析下区别，作用等等

gpt 打得不好。

- **Paxos：** Paxos 是由Leslie Lamport于1998年提出的，是较早的分布式一致性算法之一。它的论文较为复杂，理解和实现相对困难。
- **Raft：** Raft 是由Diego Ongaro和John Ousterhout于2013年提出的，旨在提供一种更易理解和实现的分布式一致性算法。Raft 的设计目标之一是使分布式系统的一致性算法更加容易教授和理解。

#### raft是强一致的吗？

是。





## MQ



RocketMQ 和 卡夫卡 都是 拉的实现

推的实现 activi mq



#### RocketMQ的数据存储格式是什么样的



来自本命年哥们的面经：https://q7mpar7ufz.feishu.cn/docx/OoRbdMiDMoi9wyxxc3bcJnEin5g

RocketMQ的数据存储格式是基于物理文件的存储模型，主要分为两种存储方式：CommitLog和ConsumeQueue。

1. CommitLog：
   1. CommitLog是RocketMQ用来存储消息的主要方式，所有生产者发送的消息都会被追加到CommitLog中。每条消息在CommitLog中占用固定大小的空间，包含消息的长度、消息的内容和一些元数据信息。
   2. CommitLog采用顺序写入的方式，保证了写入性能的高效性。这样的存储方式对于消息的持久化非常重要，即使在高并发的情况下也能保证消息的可靠存储。
2. ConsumeQueue：
   1. ConsumeQueue是RocketMQ用来存储消费队列的数据结构，用于保存消费进度和消费索引。每个主题的每个消息队列都对应一个ConsumeQueue，用于记录消费者对该消息队列中消息的消费情况。
   2. ConsumeQueue存储的是消息的偏移量，消费者消费消息后，会更新对应消息队列上的ConsumeQueue，表示已经消费了该消息，从而确保消息不会被重复消费。

除了CommitLog和ConsumeQueue外，RocketMQ还包含了其他辅助文件，如IndexFile、CheckpointFile等，用于辅助消息的索引和数据恢复。这些存储文件的结构和格式都是经过精心设计，以保证高性能、高可用性和数据的一致性。通过合理的存储格式，RocketMQ实现了高吞吐量的消息存储和传递，并保障了消息的可靠性和顺序性。





RocketMQ使用一种称为CommitLog的数据存储格式来持久化消息。CommitLog是RocketMQ的核心组件之一，它用于将消息以日志的形式存储在磁盘上，以确保消息的持久性和可恢复性。以下是RocketMQ CommitLog的一些关键特点和存储格式：

1. **顺序写入**：CommitLog以追加方式顺序写入消息，这有助于提高写入性能。每个消息都附加到CommitLog的末尾，而不是随机写入。
2. **消息索引**：为了快速检索消息，CommitLog还维护了一个消息索引，它存储了消息的偏移量和物理偏移量。消息索引允许RocketMQ快速定位和读取消息。
3. **刷盘策略**：RocketMQ支持不同的刷盘策略，以确保消息被持久化到磁盘。常见的刷盘策略包括同步刷盘和异步刷盘。同步刷盘要求消息在写入CommitLog后立即刷盘，而异步刷盘可以在后台批量刷盘，提高了写入性能。
4. **消息存储格式**：每个消息在CommitLog中的存储格式通常包括以下几个部分：
   - 消息长度（4字节）：指示消息内容的长度。
   - 消息内容（N字节）：实际的消息数据。
   - 剩余部分：包括一些元数据，如消息标志、消息属性、队列ID等。
5. **物理文件**：CommitLog的数据存储在一系列物理文件中，每个物理文件通常包含多个消息。当一个物理文件达到一定大小后，RocketMQ会创建一个新的物理文件来存储消息。
6. **日志文件切换**：为了确保消息数据不断写入，RocketMQ会定期切换到新的CommitLog文件。这有助于管理磁盘空间和提高性能。

总之，RocketMQ的数据存储格式CommitLog采用了一种高性能的追加写入方式，结合消



**下边来自 guide 给的 yes 的 mq  pdf：**

RocketMQ 的存储和速度快的原因：

顺序写盘，整体来看是顺序读盘，并且使用了 mmap，不是真正的零拷贝。又因为页缓存的不确定性和

mmap 惰性加载(访问时缺页中断才会真正加载数据)，用了文件预先分配和文件预热即每页写入一个0

字节，然后再调用 mlock 和 madvise(MADV_WILLNEED) 。



从发送消息来说 RocketMQ 用到了 mmap + write 的方式，并且通过预热来减少大文件 mmap 因为缺

页中断产生的性能问题。而



gpt。。。

`mmap`（内存映射）技术是一种操作系统提供的高级内存管理技术，它允许应用程序将文件或其他设备映射到其地址空间中，从而可以直接读取和写入内存映射区域，而无需通过常规的文件读写操作。

以下是`mmap`技术的一些关键特点和用途：

1. **文件映射**：`mmap`最常见的用途是将文件映射到**进程的地址空间中**。这意味着应用程序可以将文件的内容映射到内存中的一块区域，然后通过简单的内存操作来访问文件数据，**而不需要使用`read`和`write`等文件I/O操作。这可以显著提高文件读写的性能，特别是对于大文件。**
2. **零拷贝**：`mmap`技术通常与零拷贝（zero-copy）一起使用，因为文件数据直接映射到内存，而不需要中间的数据缓冲区。这减少了数据复制的需要，提高了I/O性能。
3. **共享内存**：`mmap`还可以用于实现进程间共享内存。多个进程可以映射相同的文件到各自的地址空间，从而实现进程间通信。这在高性能计算和多进程应用程序中非常有用。
4. **内存映射文件**：除了文件，`mmap`还可以用于将其他设备（如磁盘分区或字符设备）映射到内存中，使应用程序可以像访问内存一样访问这些设备。这对于实现高性能的数据处理任务很有用。
5. **延迟加载**：`mmap`还支持延迟加载，即在访问映射区域的特定部分时才会将相关数据从磁盘读入内存。这可以减少应用程序启动时间和内存占用。

尽管`mmap`技术提供了许多优点，但也需要小心使用，因为不当的使用可能导致内存泄漏、性能问题或数据一致性问题。应用程序需要确保正确地映射和解除映射内存区域，并处理可能的错误情况。在多线程环境中使用`mmap`时，还需要考虑并发访问和同步问题。不过，当正确使用时，`mmap`技术可以显著提高应用程序的性能和效率。







谷歌：https://blog.51cto.com/u_15301988/3081832

mmap() 是一个系统调用函数，本质是一种进程虚拟内存的映射方法，可以将一个文件、一段物理内存或者其它对象映射到进程的虚拟内存地址空间。实现这样的映射关系后，进程就可以采用指针的方式来读写操作这一段内存，进而完成对文件的操作，而不必再调用 read/write 等系统调用函数了。



 mmap 也常被用的 “零拷贝” 场景中。

mmap 优点总结
1、减少了数据的拷贝次数，用内存读写取代 I/O 读写，提高了文件读取效率。
2、实现了用户空间和内核空间的高效交互（映射）方式。各自的空间修改操作都会直接反映在共享（Shared）区域内，从而被对方空间及时捕捉到。
3、提供不同进程间共享内存及相互通信的方式。无论是父子进程，还是无亲缘关系的进程之间，都可以将自身的用户空间映射到同一个文件或匿名映射到同一片区域。从而通过各自对映射区域的改动，达到进程间通信和进程间共享的目的。例如：进程 A、B 都映射了区域 Z，当 A 第一次读取 C 时，通过缺页机制从磁盘中复制文件页到共享内存；当 B 再读 C 的相同页面时，虽然也会产生缺页异常，但是不再需要从磁盘中复制文件过来，而可直接使用已经保存在内存中的文件数据。

4、可用于实现高效的大规模数据传输。通常的，内存空间不足是制约大数据操作的一个方面，解决方案可以是借助硬盘空间协助操作，补充内存空间的不足。但是也会进一步的造成了大量的文件 I/O 操作，极大的影响了执行效率。这个问题可以通过 mmap 映射很好的解决，但凡需要用磁盘空间代替内存的时候，mmap 都可以发挥其功效。





## 系统设计

#### 限流

高赞：https://juejin.cn/post/6844904161604009997

https://blog.51cto.com/knifeedge/5786613



#### 雪花算法

缺点：

**时钟回拨问题**：如果系统时钟发生回拨，可能会导致生成的ID不是严格递增的，需要注意处理这种情况。

**有限的容量**：机器ID和序列号的位数限制了可以支持的机器数和每毫秒生成的ID数，虽然通常足够，但在极端情况下可能需要考虑。



时钟回拨问题：时间回拨导致 id 重复或不是严格递增的，机器容量上限 限制 id 生成量。



# 字节

字节后端9.15一面凉经

https://www.nowcoder.com/discuss/532169054388260864?sourceSSR=users



TCP为什么是三次握手，结束却是4次挥手

```
TCP（Transmission Control Protocol）的三次握手和四次挥手过程是为了建立和终止网络连接时保证通信的可靠性和数据一致性。

三次握手（Three-Way Handshake）：

客户端向服务器发送连接请求（SYN）：客户端发送一个带有SYN（同步序列号）标志的TCP报文段，请求建立连接。
服务器响应（ACK + SYN）：服务器收到客户端的请求后，回复一个带有SYN和ACK标志的报文段，表示同意建立连接，并确认客户端的序列号。
客户端响应（ACK）：客户端收到服务器的确认后，发送一个带有ACK标志的报文段，表示连接已建立。
三次握手完成后，双方都知道连接已建立，可以开始数据传输。

四次挥手（Four-Way Handshake）：

客户端发送结束请求（FIN）：客户端发送一个带有FIN标志的报文段，表示它没有更多的数据要发送，但仍然可以接收数据。
服务器响应（ACK）：服务器收到客户端的结束请求后，发送一个带有ACK标志的报文段，表示已接收到客户端的结束请求。
服务器发送结束请求（FIN）：服务器在关闭其数据传输通道之前，也会发送一个带有FIN标志的报文段，告知客户端它不再发送数据。
客户端响应（ACK）：客户端收到服务器的结束请求后，发送一个带有ACK标志的报文段，表示已接收到服务器的结束请求。
四次挥手的目的是确保在关闭连接之前，双方都有机会完成未完成的数据传输并通知对方。这是为了保证数据的完整性和可靠性。在四次挥手完成后，连接被完全关闭。

需要注意的是，有些情况下，TCP连接可能会经历更多的状态和报文交换，具体取决于网络条件和应用程序需求。上述的三次握手和四次挥手是最基本和常见的情况。
```

- 了解虚拟内存吗？虚拟内存怎么实现的？

程序



听过缺页中断吗？讲一下什么是缺页中断。



进程间通信方式有哪些？

你知道进程间通信最快的方式是什么吗？共享内存

共享内存，具体是怎么实现的，处于用户态还是内核态？



如果两个进程同时操作共享内存，会有什么问题？



那如何解决进程间的并发同步，有哪些方式？

如何快速定位内存泄漏问题？先回答一下什么是内存泄漏？









# 快手

比较好：快手一、二、三、hr面，许愿意向

https://www.nowcoder.com/discuss/524334635040374784?sourceSSR=users





# 大厂汇总

https://www.nowcoder.com/discuss/532303076607197184?sourceSSR=enterprise